<?xml version="1.0"?>
<!DOCTYPE sun SYSTEM "docs.dtd" [

  <!-- Define some character constants. -->
  <!ENTITY column.id.char '$'>

  <!-- Define automatically generated text entities. -->
  <!ENTITY jel.func.docs SYSTEM "jel-javadocs.xml">

  <!-- Define external URLs. -->
  <!ENTITY URL.J2SE_DOCS "http://java.sun.com/j2se/1.4.2/docs/">

  <!ENTITY flag-verbose '
     <dt><code>-v[erbose]</code></dt>
     <dd><p>May cause more information about progress to be written as
         the command runs.
         </p></dd>'>

  <!-- Short descriptions for each command. -->
  <!ENTITY calc-purpose 'Calculator'>
  <!ENTITY multicone-purpose 'Multiple Cone-Search Querier'>
  <!ENTITY regquery-purpose 'Registry Querier'>
  <!ENTITY tcat-purpose 'Table Concatenater'>
  <!ENTITY tcopy-purpose 'Table Format Converter'>
  <!ENTITY tcube-purpose 'N-dimensional Histogram Calculator'>
  <!ENTITY tmatch2-purpose 'Pair Crossmatcher'>
  <!ENTITY tpipe-purpose 'Generic Table Pipeline Utility'>
  <!ENTITY votcopy-purpose 'VOTable Encoding Translator'>
  <!ENTITY votlint-purpose 'VOTable Validity Checker'>

  <!-- Description of processing filters. -->
  <!ENTITY filter-docs SYSTEM 'filter-docs.xml'>

  <!-- Description of output modes. -->
  <!ENTITY mode-docs SYSTEM 'mode-docs.xml'>

  <!-- Summary paragraphs containing usage for each commmand. -->
  <!ENTITY calc-summary SYSTEM 'calc-summary.xml'>
  <!ENTITY multicone-summary SYSTEM 'multicone-summary.xml'>
  <!ENTITY regquery-summary SYSTEM 'regquery-summary.xml'>
  <!ENTITY tcat-summary SYSTEM 'tcat-summary.xml'>
  <!ENTITY tcopy-summary SYSTEM 'tcopy-summary.xml'>
  <!ENTITY tcube-summary SYSTEM 'tcube-summary.xml'>
  <!ENTITY tmatch2-summary SYSTEM 'tmatch2-summary.xml'>
  <!ENTITY tpipe-summary SYSTEM 'tpipe-summary.xml'>
  <!ENTITY votcopy-summary SYSTEM 'votcopy-summary.xml'>
  <!ENTITY votlint-summary SYSTEM 'votlint-summary.xml'>
  
  <!-- Raw usage messages for some commands. -->
  <!ENTITY stilts-usage SYSTEM 'stilts-usage.xml'>
  <!ENTITY tcopy-usage SYSTEM 'tcopy-usage.xml'>
  <!ENTITY tcopy-in-usage SYSTEM 'tcopy-in-usage.xml'>

  <!-- Usage messages for match engines. -->
  <!ENTITY matcher-sky-usage SYSTEM 'matcher-sky-usage.xml'>
  <!ENTITY matcher-skyerr-usage SYSTEM 'matcher-skyerr-usage.xml'>
  <!ENTITY matcher-sky3d-usage SYSTEM 'matcher-sky3d-usage.xml'>
  <!ENTITY matcher-exact-usage SYSTEM 'matcher-exact-usage.xml'>
  <!ENTITY matcher-1d-usage SYSTEM 'matcher-1d-usage.xml'>
  <!ENTITY matcher-2d-usage SYSTEM 'matcher-2d-usage.xml'>
  <!ENTITY matcher-2d_anis-usage SYSTEM 'matcher-2d_anisotropic-usage.xml'>
  <!ENTITY matcher-sky.1d-usage SYSTEM 'matcher-sky.1d-usage.xml'>
]>

<sun>

<docinfo>
<title>STILTS - Starlink Tables Infrastructure Library Tool Set</title>

<authorlist>
<author id="mbt"
        email="m.b.taylor@bristol.ac.uk"
        webpage="http://www.star.bristol.ac.uk/~mbt/"
        affiliation="Starlink, University of Bristol"
        >Mark Taylor</author>
</authorlist>

<docnumber>256</docnumber>

<history><version><px>$Id$</px></version></history>
<docdate>3 August 2006</docdate>

<contactlist>
<contact>STILTS web page:
         <webref url="http://www.starlink.ac.uk/stilts/"/></contact>
<contact>Author email:
         <webref url="mailto:m.b.taylor@bristol.ac.uk"
                 >m.b.taylor@bristol.ac.uk</webref></contact>
</contactlist>

</docinfo>

<!-- ................................................................. -->
<docbody>

<abstract>

<px>STILTS is a set of command-line tools for processing tabular data. 
It has been designed for, but is not restricted to, use on astronomical
data such as source catalogues.  
It contains both generic (format-independent) table processing tools and 
tools for processing VOTable documents.  Facilities offered include
format conversion, 
format validation, 
column calculation and rearrangement, 
row selection,
sorting,
crossmatching,
statistical calculations
and metadata display.
Calculations on cell data can be performed using a powerful and 
extensible expression language.
</px>

<px>The package is written in pure Java and based on 
<webref url="http://www.starlink.ac.uk/stil/">STIL</webref>,
the Starlink Tables Infrastructure Library.
This gives it high portability, support for many data formats
(including FITS, VOTable, text-based formats and SQL databases),
extensibility and scalability.  Where possible the tools are
written to accept streamed data so the size of tables which can 
be processed is not limited by available memory.
As well as the tutorial and reference information in this document,
detailed on-line help is available from the tools themselves.
</px>

<px>STILTS is available under the GNU General Public Licence.
</px>

</abstract>

<sect>
<subhead><title>Introduction</title></subhead>

<p>STILTS provides a number of command-line applications which can
be used for manipulating tabular data.
Conceptually it sits between, and uses many of the same classes as, 
the packages 
<webref url="http://www.starlink.ac.uk/stil/">STIL</webref>,
which is a set of Java APIs providing table-related functionality, and 
<webref url="http://www.starlink.ac.uk/topcat">TOPCAT</webref>,
which is a graphical application providing the user with
an interactive platform for exploring one or more tables.
This document is mostly self-contained - it covers some of the
same ground as the STIL and TOPCAT user documents 
(<docxref doc="sun252"/> and <docxref doc="sun253"/> respectively).
</p>

<p>Currently, this package consists of the following commands for generic
table manipulation:
<ul>
<li><ref id="tcopy" plaintextref="yes"><code>tcopy</code></ref>:
    &tcopy-purpose;
    </li>
<li><ref id="tpipe" plaintextref="yes"><code>tpipe</code></ref>:
    &tpipe-purpose;
    </li>
<li><ref id="tmatch2" plaintextref="yes"><code>tmatch2</code></ref>:
    &tmatch2-purpose;
    </li>
<li><ref id="tcat" plaintextref="yes"><code>tcat</code></ref>:
    &tcat-purpose;
    </li>
<li><ref id="tcube" plaintextref="yes"><code>tcube</code></ref>:
    &tcube-purpose;
    </li>
</ul>
the following commands specifically for operating on VOTable files:
<ul>
<li><ref id="votcopy" plaintextref="yes"><code>votcopy</code></ref>:
    &votcopy-purpose;
    </li>
<li><ref id="votlint" plaintextref="yes"><code>votlint</code></ref>:
    &votlint-purpose;
    </li>
</ul>
the following commands for accessing VO services:
<ul>
<li><ref id="regquery" plaintextref="yes"><code>regquery</code></ref>:
    &regquery-purpose;
    </li>
<li><ref id="multicone" plaintextref="yes"><code>multicone</code></ref>:
    &multicone-purpose;
    </li>
</ul>
and the following general purpose utility:
<ul>
<li><ref id="calc" plaintextref="yes"><code>calc</code></ref>:
    &calc-purpose;
    </li>
</ul>
More tools may be introduced in the future.
</p>

<p>There are many ways you might want to use these tools;
here are a few possibilities:
<dl>

<dt>In conjunction with TOPCAT</dt>
<dd><p>you can identify a set of processing steps using TOPCAT's interactive
    graphical facilities, and construct a script using the commands
    provided here which can perform the same steps on many 
    similar tables without further user intervention.
    </p></dd>

<dt>Format conversion</dt>
<dd><p>If you have a separate table processing engine and you want to 
    be able to output the results in a somewhat different form, 
    for instance converting it from FITS to VOTable or from
    TABLEDATA-encoded to BINARY-encoded VOTable, or to perform 
    some more scientifically substantial operation such as 
    changing units or coordinate systems, substituting bad values etc,
    you can pass the results through one of the tools here.
    Since on the whole operation is streaming, such conversion can 
    easily and efficiently be done on the fly.
    </p></dd>

<dt>Server-side operations</dt>
<dd><p>The tools provided here are suitable for use on servers, either
    to generate files as part of a web service (perhaps along the 
    lines of the <label>Format conversion</label> item above)
    or as configurable components in a server-based workflow system.
    </p></dd>

<dt>Quick look</dt>
<dd><p>You might want to examine the metadata, or a few rows,
    or a statistical summary of a table 
    without having to load the whole thing into TOPCAT or some other
    table viewer application.
    </p></dd>

</dl>
</p>

</sect>

<sect id="stilts-cmd">
<subhead><title>The <code>stilts</code> command</title></subhead>

<p>All the functions available in this package can be used from
a single command, which is usually referred to in this document 
simply as "<code>stilts</code>".  Depending on how you have installed
the package, you may just type "<code>stilts</code>",
or something like
<verbatim>
   java -jar some/path/stilts.jar
</verbatim>
or
<verbatim>
   java -classpath topcat-lite.jar uk.ac.starlink.ttools.Stilts
</verbatim>
or something else - 
this is covered in detail in <ref id="invoke"/>.
</p>

<p>In general, the form of a command is
<verbatim><![CDATA[
   stilts <stilts-flags> <task-name> <task-args>
]]></verbatim>
The forms of the parts of this command are described in the following
subsections, and details of each of the available tasks along with
their arguments are listed in the
<ref id="cmdUsage" plaintextref="yes">command reference</ref> 
at the end of this document.
Some of the commands are highly configurable and have a variety of 
parameters to define their operation.  
In many cases however, it's not complicated to use them.
For instance, to convert the data in a FITS table to VOTable format
you might write:
<verbatim><![CDATA[
   stilts tcopy cat.fits cat.vot
]]></verbatim>
</p>


<subsect id="stilts-flags">
<subhead><title>Stilts flags</title></subhead>

<p>Some flags are common to all the tasks in the STILTS package,
and these are specified after the <code>stilts</code> invocation itself
and before the task name.  They generally have the same effect 
regardless of which task is running.  These generic flags are as
follows:
<dl>
<dt><code>-help</code></dt>
<dd><p>Prints a usage message for the <code>stilts</code> command 
    itself and exits.  The message contains a listing of all the
    known tasks.
    </p></dd>

<dt><code>-version</code></dt>
<dd><p>Prints the STILTS version number and exits.
    </p></dd>

<dt><code>-verbose</code></dt>
<dd><p>Causes more verbose information to be written during operation.
    Specifically, what this does is to boost the logging level by 
    one notch.  It may be specified multiple times to increase verbosity
    further.
    </p></dd>

<dt><code>-disk</code></dt>
<dd><p>Encourages the command to use temporary files on disk for caching
    large amounts of data rather than doing it in memory.
    This is a good flag to try if you are running out of memory.
    This flag is in most cases equivalent to specifying the system
    property <code>-Dstartable.storage=disk</code>.
    </p></dd>

<dt><code>-debug</code></dt>
<dd><p>Sets up output suitable for debugging.  The most visible consequence
    of this is that if an error occurs then a full stacktrace is output, 
    rather than just a user-friendly report.
    </p></dd>

<dt><code>-prompt</code></dt>
<dd><p>Most of the STILTS commands have a number of parameters which
    will assume sensible defaults if you do not give them explicit
    values on the command line.  If you use the <code>-prompt</code> flag,
    then you will be prompted for every parameter you have not 
    explicitly specified to give you an opportunity to enter a value
    other than the default.
    </p></dd>

<dt><code>-batch</code></dt>
<dd><p>Some parameters will prompt you for their values, even if they 
    offer legal defaults.  If you use the <code>-batch</code> flag,
    then you won't be prompted at all.
    </p></dd>

</dl>
</p>

<p>If you are submitting an error report, please include the result of
running <code>stilts -version</code> and the output of the troublesome
command with the <code>-debug</code> flag specified.
</p>

</subsect>

<subsect id="task-name">
<subhead><title>Task Names</title></subhead>

<p>The <code>&lt;task-name&gt;</code> part of the command line is the
name of one of the tasks listed in <ref id="cmdUsage"/> - currently 
the available tasks are:
<ul>
<li><code>calc</code></li>
<li><code>multicone</code></li>
<li><code>regquery</code></li>
<li><code>tcat</code></li>
<li><code>tcopy</code></li>
<li><code>tcube</code></li>
<li><code>tmatch2</code></li>
<li><code>tpipe</code></li>
<li><code>votcopy</code></li>
<li><code>votlint</code></li>
</ul>
</p>

</subsect>

<subsect id="task-args">
<subhead><title>Task Arguments</title></subhead>

<p>The <code>&lt;task-args&gt;</code> part of the command line is a
list of parameter assignments, 
each giving the value of one of the named parameters belonging to 
the task which is specified in the <code>&lt;task-name&gt;</code> part.
</p>

<p>The general form of each parameter assignment is
<verbatim><![CDATA[
   <param-name>=<param-value>
]]></verbatim>
If you want to set the parameter to the null value, which is legal for
some but not all parameters, use the special string "<code>null</code>".
In some cases you can optionally leave out the <code>&lt;param-name&gt;</code>
part of the assignment (i.e. the parameter is positionally determined); 
this is indicated in the task's usage description if the parameter
is described like <code>[&lt;param-name&gt;=]&lt;param-value&gt;</code>
rather than <code>&lt;param-name&gt;=&lt;param-value&gt;</code>.
If the <code>&lt;param-value&gt;</code> contains spaces or other special
characters, then in most cases, such as from the Unix shell, you will
have to quote it somehow.  How this is done depends on your platform,
but usually surrounding the whole value in single quotes will do the trick.
</p>

<p>Tasks may have many parameters, and you don't have to set all of
them explicitly on the comand line.  For a parameter which you don't
set, two things can happen.  In many cases, it will default to some
sensible value.  Sometimes however, you may be prompted for the value
to use.
In the latter case, a line like this will be written to the terminal:
<verbatim>
   matcher - Name of matching algorithm [sky]:
</verbatim>
This is prompting you for the value of the parameter named 
<code>matcher</code>.  "Name of matching algorithm" is a short 
description of what that parameter does.  "<code>sky</code>" is
the default value (if there is no default, no value will appear
in square brackets).
At this point you can do one of four things:
<ul>
<li>Hit return - this will select the default value if there is one.
    If there is no default, this is equivalent to entering 
    "<code>null</code>".</li>
<li>Enter a value for the parameter explicitly.
    The special value "<code>null</code>" means the null value,
    which is legal for some, but not all parameters.
    If the value you enter is not legal, you will see an error 
    message and you will be invited to try again. </li>
<li>Enter "<code>help</code>" or a question mark "<code>?</code>".
    This will output a message
    giving a detailed description of the parameter
    and prompt you again.</li>
<li>Bail out by hitting ctrl-C or whatever is usual on your platform.</li>
</ul>
Under normal circumstances, most parameters which have a legal default
value will default to it if they are not set on the command line,
and you will only be prompted for those where there is no default or
the program thinks there's a good chance you might not want to use it.
You can influence this however using flags to the <code>stilts</code>
command itself (see <ref id="stilts-flags"/>). 
If you supply the <code>-prompt</code> flag, then you will be prompted
for every parameter you have not explicitly set.  If you supply
<code>-batch</code> on the other hand, you won't be prompted for 
any parameters (and if you fail to set any without legal default
values, the task will fail).
</p>

<p>If you want to see the actual values of the parameters for a task
as it runs,
including prompted values and defaulted ones 
which you haven't specified explicitly,
you can use the <code>-verbose</code> flag after the <code>stilts</code>
command:
<verbatim><![CDATA[
   % stilts -verbose tcopy cat.fits cat.vot ifmt=fits
   INFO: tcopy in=cat.fits out=cat.vot ifmt=fits ofmt=(auto)
]]></verbatim>
</p>

<p>Extensive help is available from <code>stilts</code> 
itself about task and its parameters, as described in the next section.
</p>

</subsect>

<subsect>
<subhead><title>Getting help</title></subhead>

<p>As well as the command descriptions in this document
(especially the reference section <ref id="cmdUsage"/>)
you can get help for STILTS usage from the command itself.
Typing
<verbatim>
   stilts -help
</verbatim>
results in this output:
<verbatim>&stilts-usage;</verbatim>
</p>

<p>For help on the individual tasks, including their parameter lists,
you can supply the word <code>help</code>
after the task name, so for instance
<verbatim>
   stilts tcopy help
</verbatim>
results in
<verbatim>&tcopy-usage;</verbatim>
</p>

<p>Finally, you can get help on any of the parameters of a task
by writing <code>help=&lt;param-name&gt;</code>, like this:
<verbatim>
   stilts tcopy help=in
</verbatim>
gives
<verbatim>&tcopy-in-usage;</verbatim>
</p>

<p>In some cases, as described in <ref id="task-args"/>, you will
be prompted for the value of a parameter with a line something like this:
<verbatim>
   matcher - Name of matching algorithm [sky]:
</verbatim>
In this case, if you enter "<code>help</code>" or a question mark,
then the parameter help entry will be printed to the screen, and 
the prompt will be repeated.
</p>

<p>For more detailed descriptions of the tasks, which includes
explanatory comments and examples as well as the information above,
see the full task descriptions in the
<ref id="cmdUsage" plaintextref="yes">Command Reference</ref>.
</p>

</subsect>

</sect>


<sect id="invoke">
<subhead><title>Invocation</title></subhead>

<p>There are a number of ways of invoking the <code>stilts</code> command,
depending on how you have installed the package.
If you're using a Unix-like operating system,
the easiest way is to use the <code>stilts</code> script.
If you have a full starjava installation it is in the 
<code>starjava/bin</code> directory.
Otherwise you can download it separately from wherever you got your
STILTS installation in the first place, or find it 
at the top of the <code>stilts.jar</code> or <code>topcat-*.jar</code>
that contains your STILTS installation, so do something like
<verbatim>
   unzip stilts.jar stilts
   chmod +x stilts
</verbatim>
to extract it (if you don't have <code>unzip</code>, 
try <code>jar xvf stilts.jar stilts</code>).
<code>stilts</code> is a simple shell script which just invokes java with the
right classpath and the supplied arguments.
</p>

<p>To run using the <code>stilts</code> script, first make sure that
both the <code>java</code> 
executable and the <code>stilts</code> script itself are on your path,
and that the <code>stilts.jar</code> or <code>topcat-*.jar</code>
jar file is in the same directory as <code>stilts</code>.
Then the form of invocation is:
<verbatim><![CDATA[
   stilts <java-flags> <stilts-flags> <task-name> <task-args>
]]></verbatim>
A simple example would be:
<verbatim>
   stilts votcopy format=binary t1.xml t2.xml
</verbatim>
in this case, as often, there are no <code>&lt;java-flags&gt;</code> or
<code>&lt;stilts-flags&gt;</code>.
If you use the <code>-classpath</code>
argument or have a CLASSPATH environment variable set, 
then classpath elements thus specified will be added to the classpath
required to run the command.
The examples in the 
command descriptions below use this form for convenience.
</p>

<p>If you don't have a Unix-like shell available however,
you will need to invoke
Java directly with the appropriate classes on your classpath.
If you have the file <code>stilts.jar</code>, in most cases you can 
just write:
<verbatim><![CDATA[
   java <java-flags> -jar stilts.jar <stilts-flags> <task-name> <task-args>
]]></verbatim>
which in practice would look something like
<verbatim>
   java -jar /some/where/stilts.jar votcopy format=binary t1.xml t2.xml
</verbatim>
</p>

<p>In the most general case, Java's <code>-jar</code> flag might be
no good, for one of the following reasons:
<ol>
<li>You have the classes in some form other than the <code>stilts.jar</code>
    file (such as <code>topcat-full.jar</code>)</li>
<li>You need to specify some extra classes on the classpath, which is
    required e.g. for use with 
    <ref id="jdbcConfig" plaintextref="yes">JDBC</ref> 
    or if you are 
    <ref id="jelExtend" plaintextref="yes">extending the commands</ref>
    using your own classes at runtime</li>
</ol>
In this case, you will need an invocation of this form:
<verbatim><![CDATA[
   java <java-flags> -classpath <class-path> 
        uk.ac.starlink.ttools.Stilts <stilts-flags> <task-name> <task-args>
]]></verbatim>
The example above in this case would look something like:
<verbatim>
   java -classpath /some/where/topcat-full.jar uk.ac.starlink.ttools.Stilts 
        votcopy format=binary t1.xml t2.xml
</verbatim>
</p>

<p>The 
<code>&lt;stilts-flags&gt;</code>,
<code>&lt;task-name&gt;</code> and
<code>&lt;task-args&gt;</code> 
parts of these invocations are explained in <ref id="stilts-cmd"/>,
and the 
<code>&lt;class-path&gt;</code> and
<code>&lt;java-flags&gt;</code>
parts are explained in the following subsections.
</p>

<subsect id="jvmClasspath">
<subhead><title>Class Path</title></subhead>

<p>The classpath is the list of places that Java looks to find
the bits of compiled code that it uses to run an application.
Depending on how you have done your installation the core STILTS
classes could be in various places, but they are probably in a
file with one of the names 
<code>stilts.jar</code>,
<code>topcat-lite.jar</code> or
<code>topcat-full.jar</code>.
The full pathname of one of these files can therefore be used as
your classpath.  In some cases these files are self-contained and
in some cases they reference other jar files in the filesystem -
this means that they may or may not continue to work if you 
move them from their original location.
</p>

<p>Under certain circumstances the tools might need additional classes,
for instance:
<ul>
<li>JDBC drivers (see <ref id="jdbcConfig"/>)</li>
<li>Providing extended algebraic functions 
    (see <ref id="jelExtend"/>)</li>
<li>Installing I/O handlers for new table formats
    (see <docxref doc="sun252" loc="pluggableIO"/>)</li>
</ul>
In this case the classpath must contain a list of all the jar files in which
the required classes can be found, separated by colons (unix) or
semicolons (MS Windows).  Note that even if all your jar files
are in a single directory you can't use the name of
that directory as a class path - you must name each jar file,
separated by colons/semicolons.
</p>

</subsect>

<subsect id="jvmArgs">
<subhead><title>Java Flags</title></subhead>

<p>In most cases it is not necessary to specify any additional 
arguments to the Java runtime, but it can be useful in certain
circumstances.  The two main kinds of options you might want to
specify directly to Java are these:

<dl>

<dt>System properties</dt>
<dd><p>System properties are a way of getting information into the
    Java runtime from the outside, rather like environment variables.
    There is a list of the ones which have significance to STILTS 
    in <ref id="sysProperties"/>.  You can set them from the 
    command line using a flag of the form <code>-Dname=value</code>.
    So for instance to ensure that temporary files are written to
    the <code>/home/scratch</code> directory, you could use the flag
    <verbatim>
   -Djava.io.tmpdir=/home/scratch
    </verbatim>
    </p></dd>

<dt>Memory size</dt>
<dd><p>Java runs with a fixed amount of 'heap' memory; this is 
    typically 64Mb by default.  
    If one of the tools fails with a message that says it's out of memory
    then this has proved too small for the job in hand.  You can increase the 
    heap memory with the <code>-Xmx</code> flag.  To set the heap 
    memory size to 256 megabytes, use the flag
    <verbatim>
   -Xmx256M
    </verbatim>
    (don't forget the 'M' for megabyte).  You will probably find
    performance is dreadful if you specify a heap size larger than 
    the physical memory of the machine you're running on.
    </p>

    <p>Note however that encouraging STILTS to use disk files
    rather than memory for temporary storage is often a
    better idea than boosting the heap memory - 
    this is done by specifying the <code>-disk</code> flag 
    (<code>stilts -disk &lt;task-name&gt; ...</code>),
    or possibly setting the system property 
    <code>-Dstartable.storage=disk</code> (see <ref id="stilts-flags"/>).
    </p></dd>

</dl>
</p>

<p>You can specify other options to Java such as tuning and profiling
flags etc, but if you want to do that sort of thing 
you probably don't need me to tell you about it.
</p>

</subsect>


<subsect id="sysProperties">
<subhead><title>System Properties</title></subhead>

<p>System properties are a way of getting information into the
Java runtime - they are a bit like environment variables.
There are two ways to set them when using STILTS: either
on the command line using arguments of the form
<code>-Dname=value</code> (see <ref id="jvmArgs"/>)
or in a file in your home directory called 
<code>.starjava.properties</code>, in the form of a
<code>name=value</code> line.
Thus submitting the flag
<verbatim>
   -Dvotable.strict=true
</verbatim>
on the command line is equivalent to having the following in your
<code>.starjava.properties</code> file:
<verbatim>
   #  Force strict interpretation of the VOTable standard.
   votable.strict=true
</verbatim>
</p>

<p>The following system properties have special significance to STILTS:
<dl>

<dt><code>java.io.tmpdir</code></dt>
<dd><p>The directory in which STILTS will write any temporary files it needs.
    This is usually only done if the <code>-disk</code> flag has been
    specified (see <ref id="stilts-flags"/>).
    </p></dd>

<dt><code>jdbc.drivers</code></dt>
<dd><p>Can be set to a (colon-separated) list of JDBC driver classes
    using which SQL databases can be accessed
    (see <ref id="jdbcConfig"/>).
    </p></dd>

<dt><code>jel.classes</code></dt>
<dd><p>Can be set to a (colon-separated) list of classes containing
    static methods which define user-provided
    functions for synthetic columns or subsets.
    (see <ref id="jelExtend"/>).
    </p></dd>

<dt><code>mark.workaround</code></dt>
<dd><p>If set to "true", this will work around a bug in the 
    <code>mark()</code>/<code>reset()</code> methods of some java
    <code>InputStream</code> classes.  These are rather common,
    including in Sun's J2SE system libraries.
    Use this if you are seeing errors that say something like
    "<code>Resetting to invalid mark</code>".
    Currently defaults to "false".</p></dd>

<dt><code>startable.readers</code></dt>
<dd><p>Can be set to a (colon-separated) list of custom table format input
    handler classes (see <docxref doc="sun252" loc="pluggableIO"/>).
    </p></dd>

<dt><code>startable.storage</code></dt>
<dd><p>Can be set to determine the default storage policy.
    Setting it to "<code>disk</code>" has basically the same effect as
    supplying the "<code>-disk</code>" argument on the command line
    (see <ref id="stilts-flags"/>).  Other possible values are
    "<code>memory</code>", "<code>sideways</code>" and "<code>discard</code>";
    see <docxref doc="sun252" loc="storagePolicy"/>.
    </p></dd>

<dt><code>startable.writers</code></dt>
<dd><p>Can be set to a (colon-separated) list of custom table format output
    handler classes (see <docxref doc="sun252" loc="pluggableIO"/>).
    </p></dd>

<dt><code>votable.strict</code></dt>
<dd><p>Set <code>true</code> for strict enforcement of the VOTable standard
    when parsing VOTables.  This prevents the parser from working round
    certain common errors, such as missing <code>arraysize</code>
    attributes on <code>FIELD</code> or <code>PARAM</code> 
    elements with <code>datatype="char"</code>.
    False by default.
    </p></dd>

</dl>
</p>

</subsect>

<subsect id="jdbcConfig">
<subhead><title>JDBC Configuration</title></subhead>

<p>This section describes additional configuration which must be
done to allow the commands to access SQL-compatible relational databases
for reading  or writing tables.
If you don't need to talk to SQL-type databases,
you can ignore the rest of this section.
The steps described here are the standard ones
for configuring JDBC (which sort-of stands for Java Database Connectivity),
described in more detail on
<webref url="&URL.J2SE_DOCS;guide/jdbc/">Sun's JDBC web page</webref>.
</p>

<p>To use STILTS with SQL-compatible databases you must:
<ul>
<li>Have access to an SQL-compatible database locally or over the network</li>
<li>Have a JDBC driver appropriate for that database</li>
<li>Install that driver for use with STILTS</li>
<li>Know the format the driver uses for URLs to access database tables</li>
<li>Have appropriate privileges on the database to perform the
    desired operations</li>
</ul>
Installing the driver consists of two steps:
<ol>
<li>Ensure that the classpath you are using includes this driver class
    as described in <ref id="jvmClasspath"/></li>
<li>Set the <code>jdbc.drivers</code> system property to the name of the
    driver class as described in <ref id="sysProperties"/></li>
</ol>
</p>

<p>These steps are all standard for use of the
<webref url="&URL.J2SE_DOCS;guide/jdbc/">JDBC</webref> system.
See <docxref doc="sun252" loc="jdbcConfig"/> for information
about JDBC drivers known to work with STIL (the short story is
that at least MySQL and PostreSQL will work).
</p>

<p>Here is an example of using <code><ref id="tcopy">tcopy</ref></code>
to write the results
of an SQL query on a table in a MySQL database as a VOTable:
<verbatim><![CDATA[
   stilts -classpath /usr/local/jars/mysql-connector-java.jar \
          -Djdbc.drivers=com.mysql.jdbc.Driver \
          tcopy \
          in="jdbc:mysql://localhost/db1#SELECT id, ra, dec FROM gsc WHERE mag < 9" \
          ofmt=votable gsc.vot
]]></verbatim>
or invoking Java directly:
<verbatim><![CDATA[
   java -classpath stilts.jar:/usr/local/jars/mysql-connect-java.jar \
        -Djdbc.drivers=com.mysql.jdbc.Driver \
        uk.ac.starlink.ttools.Stilts tcopy \
        in="jdbc:mysql://localhost/db1#SELECT id, ra, dec FROM gsc WHERE mag < 9" \
        ofmt=votable out=gsc.vot
]]></verbatim>
You have to exercise some care to get the arguments
in the right order here - see <ref id="invoke"/>.
</p>

<p>Alternatively, you can set some of this up beforehand to make the
invocation easier.  If you set your CLASSPATH environment variable
to include the driver jar file (and the STILTS classes if you're 
invoking Java directly rather than using the scripts), and if you
put the line
<verbatim>
   jdbc.drivers=com.mysql.jdbc.Driver
</verbatim>
in the <code>.starjava.properties</code> file in your home directory,
then you could avoid having to give the <code>-classpath</code> and 
<code>-Djdbc.drivers</code> flags respectively.
</p>

</subsect>

</sect>


<sect>
<subhead><title>Table Formats</title></subhead>

<p>The generic table commands in STILTS 
(currently <ref id="tpipe"><code>tpipe</code></ref>,
           <ref id="tcopy"><code>tcopy</code></ref>,
           <ref id="tcat"><code>tcat</code></ref>,
           <ref id="tcube"><code>tcube</code></ref>,
           <ref id="tmatch2"><code>tmatch2</code></ref>,
           <ref id="multicone"><code>multicone</code></ref> and
           <ref id="regquery"><code>regquery</code></ref>)
have no native format for table storage, they can process
data in a number of formats equally well.  
STIL has its own model of what a table
consists of, which is basically:
<ul>
<li>Some per-table metadata (parameters)</li>
<li>A number of columns</li>
<li>Some per-column metadata</li>
<li>A number of rows, each containing one entry per column</li>
</ul>
Some table formats have better facilities for storing this sort of
thing than others, and when performing conversions STILTS does 
its best to translate between them, but it can't perform the
impossible: for instance there is nowhere in a Comma-Separated Values 
file to store descriptions of column units, 
so these will be lost when converting from VOTable to CSV formats.
</p>

<p>The formats the package knows about are dependent on the input and
output handlers currently installed.  The ones installed by default
are listed in the following subsections.  More may be added in the 
future, and it is possible to install new ones at runtime - see 
the <docxref doc="sun252">STIL documentation</docxref> for details.
</p>

<subsect id="inFormats">
<subhead><title>Input Formats</title></subhead>

<p>Some of the tools in this package ask you to specify the format
of input tables using the <code>ifmt</code> parameter.
The following list gives the values usually allowed for this
(matching is case-insensitive):
<dl>

<dt><code>fits</code></dt>
<dd><p>FITS format - FITS binary or ASCII tables can be read.
    By default the first table HDU in the file will used, but this can
    be altered by supplying the HDU index after a '#' sign, 
    so "table.fits#3" means the third HDU extension.
    </p></dd>

<dt><code>colfits</code></dt>
<dd><p>Column-oriented FITS format.  This is where a table is stored as
    a BINTABLE extension which contains a single row, each cell of the
    row containing a whole column of the table it represents.
    This has different performance characteristics from normal FITS tables;
    in particular it may be considerably efficient for very large, and
    especially very wide tables where not all of the columns are required
    at any one time.
    Only available for uncompressed files on disk.
    </p></dd>

<dt><code>votable</code></dt>
<dd><p>VOTable format - any legal version 1.0 or 1.1 format 
    VOTable documents, and many illegal ones, can be read.
    By default the first <code>TABLE</code> element is used,
    but this can be altered
    by supplying the 0-based index after a '<code>#</code>' sign, 
    so "table.xml#4" means the fifth <code>TABLE</code> element in the document.
    </p></dd>

<dt><code>ascii</code></dt>
<dd><p>Plain text file with one row per column 
    in which columns are separated by whitespace.
    </p></dd>

<dt><code>csv</code></dt>
<dd><p>Comma-Separated Values format, 
    using approximately the conventions used by MS Excel.
    </p></dd>

<dt><code>tst</code></dt>
<dd><p>Tab-Separated Table format,
    as used by Starlink's GAIA and ESO's SkyCat amongst other tools.
    </p></dd>

<dt><code>ipac</code></dt>
<dd><p>IPAC Table Format.
    </p></dd>

<dt><code>wdc</code></dt>
<dd><p>World Datacentre Format (experimental).
    </p></dd>

</dl>
For more details on these formats, see the descriptions in 
<docxref doc="sun253" loc="inFormats"/>.
</p>

<p>In some cases (when using VOTable or FITS format tables) the 
tools can detect the table format automatically, and no explicit 
specification is necessary.  If this isn't the case and you omit
the format specification, the tool will fail with a suitable error
message.  It is always safe to specify the format explicitly;
this will be slightly more efficient,
and may lead to more helpful error messages in the case that the
table can't be read correctly.
</p>

</subsect>

<subsect id="outFormats">
<subhead><title>Output Formats</title></subhead>

<p>Some of the tools ask you to specify the format of output tables
using the <code>ofmt</code> parameter.
The following list gives the values usually allowed for this;
in some cases as you can see there are several variants of a given format.
You can abbreviate these names, and the first match in the list below
will be used, so for instance specifying <code>votable</code> is equivalent
to specifying <code>votable-tabledata</code> and <code>fits</code> 
is equivalent to <code>fits-plus</code>.
Matching is case-insensitive.

<dl>

<dt><code>fits-plus</code></dt>
<dd><p>FITS file; primary HDU contains a VOTable representation
    of the metadata, first extension contains a FITS binary table
    (behaves the same as <code>fits-basic</code> for most purposes)</p></dd>

<dt><code>fits-basic</code></dt>
<dd><p>FITS file; primary HDU is data-less, first extension
    contains a FITS binary table</p></dd>

<dt><code>colfits-plus</code></dt>
<dd><p>FITS file containing a BINTABLE with a single row; each cell of
    the row contains a whole column's worth of data.
    The primary HDU also contains a VOTable representation of the metadata.
    </p></dd>

<dt><code>colfits-basic</code></dt>
<dd><p>FITS file containing a BINTABLE with a single row; each cell of
    the row contains a whole column's worth of data.  The primary HDU
    contains nothing.
    </p></dd>

<dt><code>votable-tabledata</code></dt>
<dd><p>VOTable document with TABLEDATA (pure XML) encoding</p></dd>

<dt><code>votable-binary-inline</code></dt>
<dd><p>VOTable document with BINARY-encoded data inline within a 
    <code>STREAM</code> element</p></dd>

<dt><code>votable-binary-href</code></dt>
<dd><p>VOTable document with BINARY-encoded data in a separate file
    (only if not writing to a stream)</p></dd>

<dt><code>votable-fits-href</code></dt>
<dd><p>VOTable document with FITS-encoded data in a separate file
    (only if not writing to a stream)</p></dd>

<dt><code>votable-fits-inline</code></dt>
<dd><p>VOTable document with FITS-encoded data inline within a 
    <code>STREAM</code> element</p></dd>

<dt><code>ascii</code></dt>
<dd><p>Simple space-separated ASCII file format</p></dd>

<dt><code>text</code></dt>
<dd><p>Human-readable plain text (with headers and column boundaries marked
    out)</p></dd>

<dt><code>csv</code></dt>
<dd><p>Comma-Separated Value format.  
    The first line is a header which contains the column names.</p></dd>

<dt><code>csv-noheader</code></dt>
<dd><p>Comma-Separated Value format with no header line.</p></dd>

<dt><code>tst</code></dt>
<dd><p>Tab-Separated Table format.</p></dd>

<dt><code>html</code></dt>
<dd><p>Standalone HTML document containing a <code>TABLE</code> element</p></dd>

<dt><code>html-element</code></dt>
<dd><p>HTML <code>TABLE</code> element</p></dd>

<dt><code>latex</code></dt>
<dd><p>LaTeX <code>tabular</code> environment</p></dd>

<dt><code>latex-document</code></dt>
<dd><p>LaTeX standalone document containing a <code>tabular</code>
    environment</p></dd>
   
<dt><code>mirage</code></dt>
<dd><p>Mirage input format</p></dd>

</dl>
For more details on these formats, see the descriptions in 
<docxref doc="sun253" loc="outFormats"/>.
</p>

<p>In some cases the tools may guess what output format you want
by looking at the extension of the output filename you have specified.
</p>

</subsect>

</sect>


<sect id="pipes">
<subhead><title>Table Pipelines</title></subhead>

<p>Several of the tasks available in STILTS take one or more input tables,
do something or other with them, and produce an output table.
This is a pretty obvious way to go about things, and in the most
straightforward case that's exactly what happens: you name one
or more input tables,
specify the processing parameters, and name an output table;
the task then reads the input tables from disk, does the processing
and writes the output table to disk.
</p>

<p>However, many of the tasks in STILTS allow you to do pre-processing
of the input tables before the main job, post-processing of the
output table after the main job, and to decide what happens to 
the final tabular result, without any intermediate storage of the data.  
Examples of the kind of pre-processing
you might want to do are to rearrange the columns so that they
have the right units for the main task, or replace 'magic' values
such as -999 with genuine blank values; the kind of post-processing
you might want to do is to sort the rows in the output table or
delete some of the columns you're not interested in.
As for the destination of the final table, you might want to 
write it to disk, but equally you might not want to store it anywhere,
but only be interested in counting the number of rows, or seeing
the minima/maxima of a few of the columns, or you might want to
send it straight to TOPCAT or some other table viewing application
for interactive analysis.
</p>

<p>Clearly, you could achieve the same effect by using multiple
applications: preprocess your 
original input tables to write intermediate files on disk, 
run the main processing application which reads those files
from disk and writes a new output file,
run another application to postprocess the output file and
write a new final output file,
and finally do something with this such as counting the rows in it
or viewing it in TOPCAT.
However, by doing it all within a single task instead,
no intermediate results have to be stored,
and the whole sequence can be very much more efficient.
You can think of this (if it helps) like a Unix pipeline, 
except what is being streamed from the start to the end of the
pipe is not bytes, but table metadata and data.
In most cases, the table data is streamed through the pipeline a
row at a time, meaning that the amount of memory required is small
(though in some cases, for instance row sorting and crossmatching, 
this is not possible).
</p>

<p>Tasks which allow this pre/post-processing, or "filtering",
have parameters with names like "<code>cmd</code>" which you
use to specify processing steps.
Tasks with multiple input tables
(<ref id="tmatch2"><code>tmatch2</code></ref>,
 <ref id="tcat"><code>tcat</code></ref>)
have parameters called <code>icmd1</code>, <code>icmd2</code>, ...
for preprocessing the different input tables and
<code>ocmd</code> for postprocessing the output table.
<ref id="tpipe"><code>tpipe</code></ref> does nothing except
filtering, so there is no distinction between pre- and post-processing,
and its filter parameter is just called <code>cmd</code>.
<code>tpipe</code> additionally has a <code>script</code>
parameter which allows you to use a text file to write the
commands in, to prevent the command line getting too long.
In both cases there is a parameter called <code>omode</code>
which defines the "output mode", that is, what happens to the
post-processed output table that comes out of the end of the pipeline.
</p>

<p><ref id="filterSteps"/> lists the processing steps available,
and explains how to use them,
<ref id="col-id"/> and <ref id="colid-list"/> describe the syntax
used in some of these filter commands for specifying columns,
and <ref id="outModes"/> describes the available output modes.
See the examples in the
<ref id="cmdUsage">command reference</ref>,
and particularly the
<ref id="tpipeExamples" plaintextref="yes"><code>tpipe</code> examples</ref>,
for some examples putting all this together.
</p>

<subsect id="filterSteps">
<subhead><title>Processing Filters</title></subhead>

<p>This section lists the filter commands which can be used for 
table pipeline processing, in conjunction with <code>cmd</code>-
or <code>script</code>-type parameters.
</p>

<p>You can string as many of these together as you like.
On the command line, you can repeat the <code>cmd</code>
(or <code>icmd1</code>, or <code>ocmd</code>...) parameter 
multiple times, or use one <code>cmd</code> parameter and
separate different filter specifiers with semicolons ("<code>;</code>").
The effect is the same.
</p>

<p>It's important to note that each command in the sequence of
processing steps acts on the table at that point in the sequence.
Thus
<verbatim>
   stilts tpipe cmd='delcols 1; delcols 1; delcols 1'
</verbatim>
has the same effect as
<verbatim>
   stilts tpipe cmd='delcols "1 2 3"'
</verbatim>
since in the first case the columns are shifted left after
each one is deleted, so the table seen by each step has one fewer
column than the one before.
Note also the use of quotes in the latter of the examples above,
which is necessary so that the <code>&lt;colid-list&gt;</code>
of the <code>delcols</code> command is interpreted as one argument not
three separate words.
</p>

<p>The syntax of some of these arguments is described elsewhere in 
this document:
<ul>
<li><code>&lt;col-id&gt;</code>: see <ref id="col-id"/></li>
<li><code>&lt;colid-list&gt;</code>: see <ref id="colid-list"/></li>
<li><code>&lt;expr&gt;</code>: see <ref id="jel"/></li>
</ul>
</p>

<p>
&filter-docs;
</p>

</subsect>

<subsect id="col-id">
<subhead><title>Specifying a single column</title></subhead>

<p>If an argument is specified in the help text for a 
command with the symbol <code>&lt;col-id&gt;</code>
it means you must give a string which identifies one of the
existing columns in a table.
</p>

<p>There are three ways you can specify a column in this context:
<dl>
<dt>Column Name</dt>
<dd><p>The name of the column may be used if it contains no spaces
    and doesn't start with a minus character ('<code>-</code>').
    It is usually matched case insensitively.  If multiple columns
    have the same name, the first one that matches is selected.
    </p></dd>

<dt>Column Index or &column.id.char;ID</dt>
<dd><p>The index of the column may always be used; this is a useful
    fallback if the column name isn't suitable for some reason.
    The first column is '1', the second is '2' and so on.
    You may alternatively use the forms 
    '&column.id.char;1', '&column.id.char;2' etc.
    </p>
    <p>Tip: if counting which column has which index is giving you a
    headache, running <code>tpipe</code> with <code>omode=meta</code> or 
    <code>omode=stats</code> on the table may help.
    </p></dd>
</dl>
</p>

</subsect>

<subsect id="colid-list">
<subhead><title>Specifying a list of columns</title></subhead>

<p>If an argument is specified in the help text for a command
with the symbol <code>&lt;colid-list&gt;</code> it means you 
must give a string which identifies a list of zero, one or more
of the existing columns in a table.
The string you specify is a separated into separate tokens by
whitespace, which means that you will normally 
have to surround it in single or double quotes to ensure
that it is treated as a single argument and not several of them.
</p>

<p>Each token in the <code>colid-list</code> string may be one of
the following:
<dl>
<dt>Column Name</dt>
<dd><p>The name of a column may be used if it contains no spaces
    and doesn't start with a minus character ('<code>-</code>').
    It is usually matched case insensitively.  If multiple 
    columns have the same name, the first one that matches is selected.
    </p></dd>

<dt>Column Index or &column.id.char;ID</dt>
<dd><p>The index of the column may always be used; this is a useful
    fallback if the column name isn't suitable for some reason.
    The first column is '1', the second is '2' and so on.
    You may alternatively use the forms 
    '&column.id.char;1', '&column.id.char;2' etc.
    </p>
    <p>Tip: if counting which column has which index is giving you a
    headache, running <code>tpipe</code> with <code>omode=meta</code> or 
    <code>omode=stats</code> on the table may help.
    </p></dd>

<dt>Wildcard Expression</dt>
<dd><p>You can use a simple form of wildcard expression which expands
    to any columns in the table whose names match the pattern.
    Currently, the only special character is an asterisk '<code>*</code>'
    which matches any sequence of characters.  To match an unknown
    sequence at the start or end of the string an asterisk must be
    given explicitly.  Other than that, matching is usually 
    case insensitive.  The order of the expanded list is the same
    as the order in which the columns appear in the table.
    </p>

    <p>Thus "<code>col*</code>" will match columns named 
    <code>col1</code>, <code>Column2</code> and <code>COL_1024</code>,
    but not <code>decOld</code>.
    "<code>*MAG*</code>" will match columns named
    <code>magnitude</code>, <code>ABS_MAG_U</code> and <code>JMAG</code>.
    "<code>*</code>" on its own 
    expands to a list of all the columns of the table in order.
    </p></dd>
</dl>
</p>

<p>Specifying a list which contains a given column more than once is
not usually an error, but what effect it has depends on the 
function you are executing.
</p>

</subsect>

<subsect id="outModes">
<subhead><title>Output Modes</title></subhead>

<p>This section lists the output modes which can be used as
the value of the <code>omode</code> parameter of 
<code><ref id="tpipe">tpipe</ref></code> and other commands.
Typically, having produced a result table by pipeline processing 
an input one, you will write it out by specifying 
<code>omode=out</code> (or not using the <code>omode</code> parameter at all -
<code>out</code> is the default).  However, you can do other things
such as calculate statistics, display metadata, etc.  In some of
these cases, additional parameters are required.  The different 
output modes are listed below.
</p>

<p>
&mode-docs;
</p>

</subsect>


</sect>


<sect id="match">
<subhead><title>Crossmatching</title></subhead>

<p>STILTS offers flexible and efficient facilities for crossmatching tables.
Crossmatching is identifying different rows, which may be in the
same or different tables, that refer to the same item.
In an astronomical context such an item is usually, 
though not necessarily, an astronomical source or object.
This operation corresponds to what in database terminology 
is called a <em>join</em>.
</p>

<p>There are various complexities to specifying such a match.
In the first place you have to define what is the condition that
must be satisfied for two rows to be considered matching.
In the second place you must decide what happens if, for a given row,
more than one match can be found.  Finally, you have to decide what
to do having worked out what the matched rows are; the result will
generally be presented as a new output table, but there are various
choices about what columns and rows it will consist of.
Some of these issues are discussed in this section, and others
in the reference sections on the tools themselves in <ref id="cmdUsage"/>.
</p>

<p>Matching can in general be a computationally intensive process.
The algorithm used by STILTS, except in pathological cases, 
scales as <m>O(N log(N))</m> or thereabouts,
where <m>N</m> is the total number of rows in all the tables being matched.
No preparation (such as sorting) is required on the tables prior to
invoking the matching operation.
It is reasonably fast; for instance an RA, Dec positional match
of two 10<sup>5</sup>-row catalogues takes of the order of 60 seconds
on current (2005 laptop) hardware.  Attempting matches with large tables can 
lead to running out of memory; the calculation just mentioned required a
java heap size of around 200Mb (<code>-Xmx200M</code>).
<!--
   stilts -Xmx200M tmatch2 \
      in1=2dfgrs_ngp.fits \
      in2=2dfgrs_spectro.fits \
      icmd1='addskycoords -inunit rad -outunit deg fk5 fk5 \
                          RA2000 DEC2000 RA DEC' \
      icmd2='addskycoords -inunit rad -outunit deg fk5 fk5 \
                          RA2000 DEC2000 RA DEC' \
      matcher=sky params=3 values1='RA DEC' values2='RA DEC' \
      join=1and2 find=best \
      ocmd='addcol RA_DIFF ra_1-ra_2; addcol DEC_DIFF dec_1-dec_2' \
      omode=stats
 -->
</p>

<p>In the current release of STILTS the only crossmatching task is 
<ref id="tmatch2"><code>tmatch2</code></ref> which finds matches
between pairs of tables.  In future versions however facilities for 
finding matches within the same table, and in more than two tables,
will be introduced.
</p>

<subsect id="MatchEngine">
<subhead><title>Match Criteria</title></subhead>

<p>Determining whether one row represents the same item as another
is done by comparing the values in certain of their columns to see
if they are the same or similar.
The most common astronomical case is to say that two rows match if
their celestial coordinates (right ascension and declination) are
within a given small radius of each other on the sky.
There are other possibilities; for instance the coordinates to compare
may be in a Cartesian space, or have a higher (or lower) dimensionality
than two, or the match may be exact rather than within an error radius....
</p>

<p>To determine the matching criteria, you set the values of the 
following parameters of <code>tmatch2</code>:
<dl>
<dt><code>matcher</code></dt>
<dd><p>Name of the match criteria type.
    </p></dd>
<dt><code>params</code></dt>
    <dd><p>Fixed value(s) giving the parameters of the match 
    (typically an error radius).  If more than one value is required,
    the values should be separated by spaces.
    </p></dd>
<dt><code>values*</code></dt>
    <dd><p>Expressions to be compared between rows.  This will typically
    contain the names of one or more columns, but each element may be
    an algebraic expression (see <ref id="jel"/>) rather than just a 
    column name if required.
    If more than one value is required, the values should be separated
    by spaces.
    There is one of these parameters for each table taking part in the 
    match, so for <code>tmatch2</code> you must specify both 
    <code>values1</code> and <code>values2</code>.
    </p></dd>
</dl>
</p>

<p>For example, suppose we wish to locate objects in two tables which are
within 3 arcseconds of each other on the sky.  One table has columns
RA and DEC which give coordinates in degrees, and the other has columns
RArad and DECrad which give coordinates in radians.  These are the
arguments which would be used to tell <code>tmatch2</code> what the match
criteria are:
<verbatim>
   matcher=sky
   params=3
   values1='RA DEC'
   values2='radiansToDegrees(RArad) radiansToDegrees(DECrad)'
</verbatim>
It is clearly important that corresponding values are comparable
(in the same units) between the tables being matched,
and in geometrically sensitive cases such as matching
on the sky, it's important that they are the units expected by the
matcher as well.  To determine what those units are, either consult
the roster below, or run the following command:
<verbatim>
   stilts tmatch2 help=matcher
</verbatim>
which will tell you about all the known matchers and their associated
<code>params</code> and <code>values*</code> parameters.
</p>

<p>Here is a list of all the basic <code>matcher</code> types and the
requirements of their associated <code>params</code> and 
<code>values*</code> parameters.  The units of the required values
are given where significant.
<dl>

<dt>&matcher-sky-usage;</dt>
<dd><p>Comparison of positions on the celestial sphere with a fixed error
    radius.  
    Rows are considred to match when the 
    two <code>ra</code>, <code>dec</code> positions are within 
    <code>max-error</code> arcseconds of each other along a great circle.
    </p></dd>

<dt>&matcher-skyerr-usage;</dt>
<dd><p>Comparison of positions on the celestial sphere with per-row 
    error radii.
    Rows are considered to match when the separation between the
    two <code>ra</code>, <code>dec</code> positions is smaller than 
    <em>both</em> the fixed <code>max-error</code> value 
    <em>and</em> the sum of the two per-row <code>error</code> values.
    If either of the <code>error</code> values is blank,
    then any separation up to <code>max-error</code> is considered a match.
    According to these rules, you might decide to set <code>max-error</code>
    to an arbitarily large number so that only the sum of <code>error</code>s
    will determine the actual match criteria.
    However please <em>don't</em> do this, since <code>max-error</code>
    also functions as a tuning parameter for the matching algorithm,
    and ought to be reasonably close to the actual maximum acceptable
    separation.
    </p></dd>

<dt>&matcher-sky3d-usage;</dt>
<dd><p>Comparison of positions in the sky taking account of
    distance from the observer.
    The position in three-dimensional space is calculated for each 
    row using the <code>ra</code>, <code>dec</code> and <code>distance</code>
    as spherical polar coordinates, where <code>distance</code> is the
    distance from the observer along the line of sight.
    Rows are considered to match when their positions in this space are
    within <code>error</code> units of each other.
    The units of <code>error</code> are the same as those of 
    <code>distance</code>.
    </p></dd>

<dt>&matcher-exact-usage;</dt>
<dd><p>Comparison of arbitrary key values for exact equality.
    Rows are considered to match only if the values in their 
    <code>matched-value</code> columns are exactly the same.
    These values can be strings, numbers, or anything else.
    A blank value never matches, not even with another blank one.
    Since the <code>params</code> parameter holds no values, 
    it does not have to be specified.
    </p></dd>

<dt>&matcher-1d-usage;</dt>
<dd><p>Comparison of positions in 1-dimensional Cartesian space.
    Rows are considered to match if their <code>x</code> column
    values differ by no more than <code>error</code>.
    </p></dd>

<dt>&matcher-2d-usage;</dt>
<dd><p>Comparison of positions in 2-dimensional Cartesian space.
    Rows are considered to match if the difference in their 
    (<code>x</code>,<code>y</code>) positions reckoned using
    Pythagoras is less than <code>error</code>.
    </p></dd>

<dt><verbatim><![CDATA[matcher=Nd values*='<x> <y> ...'
          params='<error>']]></verbatim></dt>
<dd><p>Comparison of positions in N-dimensional Cartesian space.
    As for <code>matcher=2d</code>, 
    but specify <code>matcher=3d</code> or whatever and
    the corresponding number of entries in the <code>values*</code> parameters.
    </p></dd>

<dt>&matcher-2d_anis-usage;</dt>
<dd><p>Comparison of positions in 2-dimensional Cartesian space using
    an anisotropic metric.
    Rows are considered to match if their (<code>x</code>,<code>y</code>)
    positions fall within an error ellipse with radii 
    <code>error-in-x</code>,<code>error-in-y</code> of each other.
    This kind of match will typically be used for non-'spatial' spaces,
    for instance (magnitude,redshift) space, in which the metrics along
    different axes are not related to each other.
    </p></dd>

<dt><verbatim><![CDATA[matcher=Nd_anisotropic values*='<x> <y> ...'
                       params='<error-in-x> <error-in-y> ...']]></verbatim></dt>
<dd><p>Comparison of positions in N-dimensional Cartesian space using
    an anisotropic metric.
    As <code>matcher=2d_anisotropic</code>,
    but specify <code>matcher=3d_anisotropic</code> or whatever
    and the corresponding number of entries in the <code>values*</code>
    and <code>params</code> parameters.
    </p></dd>

</dl>
In addition to those matching criteria listed above, you can build your
own by combining any of these.  To do this, take the two (or more)
matchers that you want to use, and separate their names with a
"<code>+</code>" character.  The <code>values*</code> parameters
of the combined matcher should then hold the concatenation of the
<code>values*</code> entries of the constituent matchers, and the
same for the <code>params</code> parameter.
So for instance the following can be used:
<dl>

<dt>&matcher-sky.1d-usage;</dt>
<dd><p>Comparison of positions on the sky with an additional scalar constraint.
    Rows are considered to match if <em>both</em>
    their <code>ra</code>, <code>dec</code> positions are within
    <code>max-error</code> arcseconds of each other along a great circle
    (as for <code>matcher=sky</code>) 
    <em>and</em>
    their <code>x</code> values differ by no more than <code>error</code>
    (as for <code>matcher=1d</code>).
    </p></dd>

</dl>
This example might be used for instance to identify objects from two
catalogues which are within a couple of arcseconds and also 0.5
blue magnitudes of each other.
Rolling your own matchers in this way can give you very flexible match
constraints.
</p>

</subsect>

</sect>


<sect id="jel">
<subhead><title>Algebraic Expression Syntax</title></subhead>

<p>The <code>tpipe</code> command allows you to use algebraic
expressions when making row selections and defining new synthetic 
columns.  They can also be used in defining the quantities to 
match against in <code>tmatch2</code>.
In both cases you are defining an expression which
has a value in each row as a function of the values in the existing
columns in that row.
This is a powerful feature which permits you to manipulate and select
table data in very flexible ways.
The syntax for entering these expressions is explained in this section.
</p>

<p>What you write are actually expressions in
the Java language, which are compiled into Java bytecode before
evaluation.  However, this does not mean that you need to be a
Java programmer to write them.  The syntax is pretty similar to C,
but even if you've never programmed in C most simple things,
and many complicated ones, are quite intutitive.
</p>

<p>The following explanation gives
some guidance and <ref id="jelExamples">examples</ref>
for writing these expressions.
Unfortunately a complete tutorial on writing Java is beyond
the scope of this document, but it should provide enough information
for even a novice to write useful expressions.
</p>

<p>The expressions that you can write are basically any function
of all the column values which apply
to a given row; the function result can then be used in 
one of <code>tpipe</code>'s commands, 
e.g.  to define the per-row value of a new column
(<code>addcol</code>, <code>replacecol</code>)
make a row selection
(<code>select</code>),
and some other places.
If the built-in operators and functions are not sufficient,
or it's unwieldy to express your function in one line of code,
it is possible to add new functions by writing your own classes -
see <ref id="jelExtend"/>.
</p>

<p>Note that since these algebraic expressions often contain spaces,
you may need to enclose them in single or double quotes so that
they don't get confused with other parts of the command string.
</p>

<p><strong>Note:</strong> if Java is running in an environment with
certain security restrictions (a security manager which
does not permit creation of custom class loaders) then algebraic
expressions won't work at all.  It's not particularly likely
that security restrictions will be in place if you are running
from the command line though.
</p>

<subsect>
<subhead><title>Referencing Column Values</title></subhead>

<p>To create a useful expression which can be evaluated for each row
in a table, you will have to refer to cells in different columns of that row.
You can do this in two ways:
<dl>
<dt>By Name</dt>
<dd><p>The Name of the column may be used if it is unique (no other column in
    the table has the same name) and if it has a suitable form.
    This means that it must have the form of a Java variable - basically
    starting with a letter and continuing with
    letters or numbers.  In particular it cannot have any spaces in it.
    The underscore and currency symbols count as
    letters for this purpose.
    Column names are treated case-insensitively.
    </p></dd>

<dt>By &column.id.char;ID</dt>
<dd><p>The "&column.id.char;ID"
    identifier of the column may always be used to refer to it;
    this is a useful fallback if the column name isn't suitable for
    some reason (for instance it contains spaces or is not unique).
    This is just a "&column.id.char;" sign followed by the column index -
    the first column is &column.id.char;1.
    </p></dd>

</dl>
</p>
<p>There is a special column whose name is "Index" and whose ID is
"&column.id.char;0". 
The value of this is the same as the row number (the first row is 1).
</p>

<p>The value of the variables so referenced will be a primitive
(boolean, byte, short, char, int, long, float, double) if the 
column contains one of the corresponding types.  Otherwise it will
be an Object of the type held by the column, for instance a String.
In practice this means: you can write the name of a column, and it will
evaluate to the numeric (or string) value that that column contains
in each row.  You can then use this in normal algebraic expressions
such as "<code>B_MAG - U_MAG</code>" as you'd expect.
</p>

</subsect>

<subsect>
<subhead><title>Null Values</title></subhead>

<p>When no special steps are taken, if a null value (blank cell)
is encountered
in evaluating an expression (usually because one of the columns
it relies on has a null value in the row in question) then the
result of the expression is also null.
</p>

<p>It is possible to exercise more control than this, but it
requires a little bit of care,
because the expressions work in terms of primitive values
(numeric or boolean ones) which don't in general have a defined null
value.  The name "<code>null</code>" 
in expressions gives you the java <code>null</code>
reference, but this cannot be matched against a primitive value
or used as the return value of a primitive expression.
</p>

<p>For most purposes, the following two tips should enable you to
work with null values:

<dl>
<dt>Testing for null</dt>
<dd><p>To test whether a column contains a null value, prepend the
    string "<code>NULL_</code>"
    (use upper case) to the column name or &column.id.char;ID.  This
    will yield a boolean value which is true if the column contains
    a blank, and false otherwise.
    </p></dd>

<dt>Returning null</dt>
<dd><p>To return a null value from a numeric expression, use the name
    "<code>NULL</code>"
    (upper case).  To return a null value from a non-numeric expression
    (e.g. a String column) use the name "<code>null</code>" (lower case).
    </p></dd>
</dl>
</p>

<p>Null values are often used in conjunction with the conditional
operator, "<code>? :</code>"; the expression
<verbatim>
   test ? tval : fval
</verbatim>
returns the value <code>tval</code> if the boolean expression <code>test</code>
evaluates true, or <code>fval</code> if <code>test</code> evaluates false.
So for instance the following expression:
<verbatim>
   Vmag == -99 ? NULL : Vmag
</verbatim>
can be used to define a new column which has the same value as the 
<code>Vmag</code> column for most values, but if <code>Vmag</code> 
has the "magic" value -99 the new column will contain a blank.
The opposite trick (substituting a blank value with a magic one) can
be done like this:
<verbatim>
   NULL_Vmag ? -99 : Vmag
</verbatim>
Some more examples are given in <ref id="jelExamples"/>.
</p>

</subsect>

<subsect>
<subhead><title>Operators</title></subhead>

<p>The operators are pretty much the same as in the C language.
The common ones are:
<dl>
<dt>Arithmetic</dt>
<dd><p>
  <dl>
  <dt><code>+</code> (add)</dt>
  <dt><code>-</code> (subtract)</dt>
  <dt><code>*</code> (multiply)</dt>
  <dt><code>/</code> (divide)</dt>
  <dt><code>%</code> (modulus)</dt>
  </dl>
</p></dd>

<dt>Boolean</dt>
<dd><p>
  <dl>
  <dt><code>!</code> (not)</dt>
  <dt><code>&amp;&amp;</code> (and)</dt>
  <dt><code>||</code> (or)</dt>
  <dt><code>^</code> (exclusive-or)</dt>
  <dt><code>==</code> (numeric identity)</dt>
  <dt><code>!=</code> (numeric non-identity)</dt>
  <dt><code>&lt;</code> (less than)</dt>
  <dt><code>&gt;</code> (greater than)</dt>
  <dt><code>&lt;=</code> (less than or equal)</dt>
  <dt><code>&gt;=</code> (greater than or equal)</dt>
  </dl>
</p></dd>

<dt>Numeric Typecasts</dt>
<dd><p>
  <dl>
  <dt><code>(byte)</code>   (numeric -> signed byte)</dt>
  <dt><code>(short)</code>  (numeric -> 2-byte integer)</dt>
  <dt><code>(int)</code>    (numeric -> 4-byte integer)</dt>
  <dt><code>(long)</code>   (numeric -> 8-byte integer)</dt>
  <dt><code>(float)</code>  (numeric -> 4-type floating point)</dt>
  <dt><code>(double)</code> (numeric -> 8-byte floating point)</dt>
  </dl>
  Note you may find the 
  <ref id="uk.ac.starlink.ttools.func.Maths" plaintextref="yes">Maths</ref> 
  conversion functions more convenient for numeric conversions than these.
</p></dd>

<dt>Other</dt>
<dd><p>
  <dl>
  <dt><code>+</code>  (string concatenation)</dt>
  <dt><code>[]</code> (array dereferencing)</dt>
  <dt><code>?:</code> (conditional switch)</dt>
  <dt><code>instanceof</code> (class membership)</dt>
  </dl>
</p></dd>
</dl>
</p>

</subsect>

<subsect id="staticMethods">
<subhead><title>Functions</title></subhead>

<p>Many functions are available for use within your expressions,
covering standard mathematical and trigonometric functions,
arithmetic utility functions, type conversions, and some more
specialised astronomical ones.
You can use them in just the way you'd expect,
by using the function name
(unlike column names, this is case-sensitive) followed by
comma-separated arguments in brackets, so
<verbatim>
    max(IMAG,JMAG)
</verbatim>
will give you the larger of the values in the columns IMAG and JMAG,
and so on.
</p>

<p>The functions available for use by default
are listed by class in the following subsections
with their arguments and short descriptions.
</p>

&jel.func.docs;

</subsect>

<subsect id="jelExamples">
<subhead><title>Examples</title></subhead>

<p>Here are some examples for defining new columns;
the expressions below could appear as the <code>&lt;expr&gt;</code> in a
<code>tpipe</code> <code>addcol</code> or <code>sortexpr</code>
<ref id="filterSteps">command</ref>).
<dl>

<dt>Average</dt>
<dd><p><verbatim>
   (first + second) * 0.5
</verbatim></p></dd>

<dt>Square root</dt>
<dd><p><verbatim>
   sqrt(variance)
</verbatim></p></dd>

<dt>Angle conversion</dt>
<dd><p><verbatim>
   radiansToDegrees(DEC_radians)
   degreesToRadians(RA_degrees)
</verbatim></p></dd>

<dt>Conversion from string to number</dt>
<dd><p><verbatim>
   parseInt(&column.id.char;12)
   parseDouble(ident)
</verbatim></p></dd>

<dt>Conversion from number to string</dt>
<dd><p><verbatim>
   toString(index)
</verbatim></p></dd>

<dt>Conversion between numeric types</dt>
<dd><p><verbatim>
   toShort(obs_type)
   toDouble(range)
</verbatim><em>or</em><verbatim>
   (short) obs_type
   (double) range
</verbatim></p></dd>

<dt>Conversion from sexagesimal to radians</dt>
<dd><p><verbatim>
   hmsToRadians(RA1950)
   dmsToRadians(decDeg,decMin,decSec)
</verbatim></p></dd>

<dt>Conversion from radians to sexagesimal</dt>
<dd><p><verbatim>
   radiansToDms(&column.id.char;3)
   radiansToHms(RA,2)
</verbatim></p></dd>

<dt>Outlier clipping</dt>
<dd><p><verbatim>
   min(1000, max(value, 0))
</verbatim></p></dd>

<dt>Converting a magic value to null</dt>
<dd><p><verbatim>
   jmag == 9999 ? NULL : jmag
</verbatim></p></dd>

<dt>Converting a null value to a magic one</dt>
<dd><p><verbatim>
   NULL_jmag ? 9999 : jmag
</verbatim></p></dd>

<dt>Taking the third scalar element from an array-valued column</dt>
<dd><p><verbatim>
   psfCounts[2]
</verbatim></p></dd>

</dl>

and here are some examples of boolean expressions that could be used
for row selection (appearing in a <code>tpipe</code> <code>select</code>
command)

<dl>
<dt>Within a numeric range</dt>
<dd><p><verbatim>
   <![CDATA[RA > 100 && RA < 120 && Dec > 75 && Dec < 85]]>
</verbatim></p></dd>

<dt>Within a circle</dt>
<dd><p><verbatim>
   &column.id.char;2*&column.id.char;2 + &column.id.char;3*&column.id.char;3 &lt; 1
   skyDistance(ra0,dec0,degreesToRadians(RA),degreesToRadians(DEC))&lt;15*ARC_MINUTE
</verbatim></p></dd>

<dt>First 100 rows</dt>
<dd><p><verbatim>
   index &lt;= 100
</verbatim>
(though you could use <code>tpipe cmd='head 100'</code> instead)</p></dd>

<dt>Every tenth row</dt>
<dd><p><verbatim>
   index % 10 == 0
</verbatim>
(though you could use <code>tpipe cmd='every 10'</code> instead)</p></dd>

<dt>String equality/matching</dt>
<dd><p><verbatim>
   equals(SECTOR, "ZZ9 Plural Z Alpha")
   equalsIgnoreCase(SECTOR, "zz9 plural z alpha")
   startsWith(SECTOR, "ZZ")
   contains(ph_qual, "U")
</verbatim></p></dd>

<dt>String regular expression matching</dt>
<dd><p><verbatim>
   matches(SECTOR, "[XYZ] Alpha")
</verbatim></p></dd>

<dt>Test for non-blank value</dt>
<dd><p><verbatim>
   ! NULL_ellipticity
</verbatim></p></dd>
</dl>
</p>

</subsect>

<subsect id="jelAdvanced">
<subhead><title>Advanced Topics</title></subhead>

<p>This section contains some notes on getting the most out of
the algebraic expressions facility.  If you're not a Java programmer,
some of the following may be a bit daunting - read on at your
own risk!
</p>

<subsubsect>
<subhead><title>Expression evaluation</title></subhead>

<p>This note provides a bit more detail for Java programmers on what
is going on here; it describes how the use
of functions in STILTS algebraic expressions relates to normal Java
code.
</p>

<p>The expressions which you write are compiled to Java bytecode
when you enter them (if there is a 'compilation error' it will be
reported straight away).  The functions listed in the previous subsections
are all the <code>public static</code> methods of the classes which
are made available by default.  The classes listed are all in the
package <code>uk.ac.starlink.ttools.func</code>.
However, the public static methods are all imported into an anonymous
namespace for bytecode compilation, so that you write
(<code>sqrt(x,y)</code> and not <code>Maths.sqrt(x,y)</code>.
The same happens to other classes that are imported (which can be
in any package or none) - their public
static methods all go into the anonymous namespace.  Thus, method
name clashes are a possibility.
</p>

<p>This cleverness is all made possible by the rather wonderful
<webref url="http://galaxy.fzu.cz/JEL/" plaintextref="yes">JEL</webref>.
</p>

</subsubsect>

<subsubsect>
<subhead><title>Instance Methods</title></subhead>

<p>There is another category of functions which can be used apart from
those listed in <ref id="staticMethods"/>.
These are called, in Java/object-oriented parlance, "instance methods"
and represent functions that can be executed on an object.
</p>

<p>It is possible to invoke any of its public
instance methods on any object
(though not on primitive values - numeric and boolean ones).
The syntax is that you place a "." followed by the method invocation
after the object you want to invoke the method on,
hence <code>NAME.substring(3)</code> instead of <code>substring(NAME,3)</code>.
If you know what you're doing, feel free to go ahead and do this.
However, most of the instance methods you're likely to want to use
have equivalents in the normal functions listed in the previous section,
so unless you're a Java programmer or feeling adventurous,
you may be best off ignoring this feature.
</p>

</subsubsect>


<subsubsect id="jelExtend">
<subhead><title>Adding User-Defined Functions</title></subhead>

<p>The functions provided by default for use with algebraic expressions,
while powerful, may not provide all the operations you need.
For this reason, it is possible to write your own extensions to the
expression language.  In this way you can specify abritrarily complicated
functions.
Note however that this will only allow you to define new columns or subsets
where each cell is a function only of the other cells in the same
row - it will not allow values in one row to be functions of values
in another.
</p>

<p>In order to do this, you have to write and compile a
(probably short) program
in the Java language.  A full discussion of how to go about this
is beyond the scope of this document, so if you are new
to Java and/or programming you may need to find a friendly local
programmer to assist (or mail the author).
The following explanation is aimed at Java programmers, but may not
be incomprehensible to non-specialists.
</p>

<p>The steps you need to follow are:
<ol>
<li>Write and compile a class containing one or more static public
    methods representing the function(s) required</li>
<li>Make this class available on the application's classpath at runtime
    as described in <ref id="jvmClasspath"/></li>
<li>Specify the class's name to the application, as the value of the
    <code>jel.classes</code>
    system property (colon-separated if there are several)
    as described in <ref id="sysProperties"/></li>
</ol>
</p>

<p>Any public static methods defined in the classes thus specified
will then be available for use.
They should be defined to take and return the relevant primitive or
Object types for the function required.
For instance a class written as follows would define a three-value average:
<verbatim>
   public class AuxFuncs {
       public static double average3( double x, double y, double z ) {
           return ( x + y + z ) / 3.0;
       }
   }
</verbatim>
and the command
<verbatim>
   stilts tpipe cmd='addcol AVERAGE "average3(&column.id.char;1,&column.id.char;2,&column.id.char;3)"'
</verbatim>
would add a new column called AVERAGE giving the average of the first
three existing columns.
Exactly how you would build this is dependent on your system,
but it might involve doing something like the following:
<ol>
<li>Writing a file called <code>AuxFuncs.java</code> 
    containing the above code</li>
<li>Compiling it using a command like "<code>javac AuxFuncs.java</code>"</li>
<li>Running <code>tpipe</code> using the flags
    "<code>stilts -classpath . -Djel.classes=AuxFuncs tpipe</code>"</li>
</ol>
</p>

</subsubsect>

</subsect>

</sect>

<appendices>

<sect id="cmdUsage">
<subhead><title>Command Reference</title></subhead>

<p>This appendix provides the reference documentation for the
commands in the package.  For each one a description of its purpose,
a list of its command-line arguments, and some examples are given.
</p>

<subsect id="calc">
<subhead><title><code>calc</code>: &calc-purpose;</title></subhead>

<p><code>calc</code> is a very simple utility for evaluating expressions.
It uses the same expression evaluator as is used in <code>tpipe</code>
and the other generic table tasks for things like creating new columns,
so it can be used as a quick test to see what expressions work,
or in order to evaluate expressions using the various algebraic
functions documented in <ref id="staticMethods"/>.
Since no table is involved, you can't refer to column names in
the expressions.
It takes one parameter, the expression to evaluate, and writes the
result to the screen.
</p>

&calc-summary;

<subsubsect>
<subhead><title>Examples</title></subhead>

<p>Here are some examples of using <code>calc</code>:
<dl>

<dt><verbatim>
stilts calc 1+2
</verbatim></dt>
<dd><p>Calculates one plus two.  Writes "3" to standard output.
    </p></dd>

<dt><verbatim>
stilts calc 'isoToMjd("2005-12-25T00:00:00")'
</verbatim></dt>
<dd><p>Works out the Modified Julian Day corresponding to Christmas 2005.
    The output is "53729.0".
    </p></dd>

</dl>
</p>

</subsubsect>

</subsect>

<subsect id="multicone">
<subhead><title><code>multicone</code>: &multicone-purpose;</title></subhead>

<p><code>multicone</code> is a utility which performs a cone search
query for each row of an input table and concatenates the results 
of all these queries together into one big output table.
You give the <label>service URL</label> for the cone search server you wish
to use, and expressions (usually column names) 
defining how to get the search parameters 
(sky position and search radius) for each row of the input table.  
The program then goes through the input table and dispatches
a cone search query to the server for each row.  
For each of these queries the service should respond with a 
VOTable containing the objects it knows about in the specified region; 
hopefully the columns will be the same or very similar for
all the different queries since they are using the same service.
The response tables aren stitched together top-to-bottom 
(in the same way as <ref id="tcat"><code>tcat</code></ref>)
and the result is output.
</p>

<p>This is in some ways like doing a positional crossmatch 
where one of the catalogues is local and the other is remote.
Because of both the network communication and the naive algorithm
however, it is only suitable if the local catalogue has a rather
small number of rows.
</p>

<p>The <label>cone search</label> protocol is not currently a formal IVOA 
standard, but it is a simple service widely implemented by catalogue servers.
A description of the protocol can be found at
<webref url="http://us-vo.org/pubs/files/conesearch.html"/>.
</p>

<p>You can locate available cone search services and their service URLs
by interrogating the <label>VO Registry</label>.
One way to do this is using the <code>regquery</code> command.
For instance, to identify registered cone search services that have
something to do with Sloan data, you could execute the folowing:
<verbatim>
    stilts regquery query="serviceType = 'CONE' and title like '%Sloan%'" \
           ocmd="keepcols 'shortName serviceUrl'" \
           ofmt=ascii
</verbatim>
Writing just <code>query="serviceType = 'CONE'"</code> with no
further qualification will give you all registered cone search services.
See the section on 
<ref id="regquery" plaintextref="yes"><code>regquery</code></ref> 
for more explanation.
</p>

<p>Note that when running, <code>multicone</code> often generates a lot
of WARNING messages.  Most of these are complaining about badly formed
VOTables being returned from the cone search services.  STILTS does its
best to work out what the service responses mean in this case, 
and usually makes a good enough job of it.
</p>

<p>This command is experimental.  It may be modified or renamed in a future
release of STILTS.
</p>

&multicone-summary;

<subsubsect>
<subhead><title>Examples</title></subhead>

<p>Here are some examples of <code>multicone</code>:
<dl>

<dt><verbatim>
stilts multicone serviceurl=http://archive.stsci.edu/hst/search.php \
                 in=messier.xml ra=RA dec=DEC sr=0.05 \
                 out=matches.xml
</verbatim></dt>
<dd><p>This queries the HST cone search service from Space Telescope for
    records within .05 degrees of each Messier object contained in a 
    local VOTable <code>messier.xml</code>.  The result is written to a
    new VOTable, <code>matches.xml</code>.  The J2000 positions of each
    record in the input file are held in columns named RA and
    DEC respectively.
    </p></dd>

<dt><verbatim>
stilts multicone \
       serviceurl='http://www.nofs.navy.mil/cgi-bin/vo_cone.cgi?CAT=NOMAD' \
       in=vizier.xml#7 \
       icmd='addskycoords -inunit sex fk4 fk5 RAB1950 DEB1950 RAJ2000 DEJ2000' \
       icmd='progress'
       ra=RAJ2000 dec=DEJ2000 sr=0.01 \
       ocmd='replacecol -units rad RA hmsToRadians(RA[0],RA[1],RA[2])' \
       ocmd='replacecol -units rad DEC dmsToRadians(DEC[0],DEC[1],DEC[2])' \
       omode=topcat
</verbatim></dt>
<dd><p>In this example some pre-processing of the input catalogue and
    post-processing of the output catalogue is performed as well as the
    multiple cone search itself.
    </p>
    <p>The input catalogue, which is the 8th TABLE element in a VOTable file,
    contains sky positions in sexagesimal FK4 (B1950) coordinates.  
    The <code>icmd=addskycoords...</code> parameter specifies a filter which
    will add new columns in FK5 (J2000) degrees, which are what the 
    multicone command requires.
    The <code>icmd=progress</code> parameter specifies a filter which
    will write progress information to the terminal so you can see how
    the queries are progressing.
    </p>
    <p>The NOMAD service specified by the <code>serviceurl</code> parameter
    used here happens to return results with the RA/DEC columns represented
    in a rather eccentric format, namely 3-element floating point arrays 
    representing (hours,minutes,seconds)/(degrees,minutes,seconds).
    The two <code>ocmd=replacecol...</code> filters replace the values of
    these columns with the scalar equivalents in radians.
    Finally, the <code>omode=topcat</code> parameter causes the result
    table to be loaded directly into TOPCAT (if it is available).
    </p>
    </dd>

<dt><verbatim>
stilts multicone serviceurl='http://archive.stsci.edu/iue/search.php?' \
                 in=queries.txt ifmt=ascii \
                 ra='&column.id.char;1' dec='&column.id.char;2' sr='&column.id.char;3' copycols='&column.id.char;4' \
                 out=found.fits
</verbatim></dt>
<dd><p>Here the input is a plain text table with four unnamed columns, 
    giving in order the right ascension, declination,
    positional error and name of target objects.
    The command carries out a cone search to the named service for
    each one.  Note in this case the search radius (<code>sr</code> parameter)
    is taken from the table and so varies for each query.
    The <code>copycols</code> parameter has the value 
    '<code>&column.id.char;4</code>',
    which means that the value of the fourth column of the input table 
    will be prepended to each row of the output table for 
    which it is responsible.
    Output is to a FITS table.
    </p></dd>
</dl>
</p>

</subsubsect>

</subsect>

<subsect id="regquery">
<subhead><title><code>regquery</code>: &regquery-purpose;</title></subhead>

<p><code>regquery</code> submits a query to the Virtual Observatory 
<label>registry</label>
and returns the result as a table containing all the records which 
match the condition specified.  The resulting table can be written out 
in any of the supported formats or otherwise processed in the usual ways.
Currently the registry used by default is the SOAP service offered
by the US NVO registry at 
<webref url="http://voservices.net/registry/registry.asmx"/>.
Because VO registries generally harvest from each other, the content of
this one can be expected to be similar to that stored in registries
maintained by other organisations.
</p>

&regquery-summary;

<subsubsect>
<subhead><title>Examples</title></subhead>

<p>Here are some examples of <code>regquery</code>:
<dl>

<dt><verbatim>
stilts regquery query="identifier like '%astrogrid%'" out=ag.xml
</verbatim></dt>
<dd><p>Retrieves all the records in the registry whose 
    <code>identifier</code> field contain the string 
    "<code>astrogrid</code>".  The '<code>%</code>' characters function
    as wildcards for the <code>like</code> operator.
    The output is written to a local VOTable file which can be examined
    or further processed later.
    </p></dd>

<dt><verbatim>
stilts regquery query="serviceType = 'SSAP'" omode=count
</verbatim></dt>
<dd><p>Queries the registry for all the records whose
       <code>serviceType</code> fields equal the string <code>SSAP</code>
       (this identifies services which support the Simple Spectral Access
       Protocol).  These records are not stored, but the 
       <code>omode=count</code> output mode counts the rows.
       This therefore tells you how many SSAP servers are registered.
       </p></dd>

<dt><verbatim>
stilts regquery query="serviceType = 'CONE' and title like '%Sloan%'" \
                ocmd="keepcols 'shortName serviceUrl'" \
                ofmt=ascii out=-
</verbatim></dt>
<dd><p>Queries the registry for all
       <webref url="http://us-vo.org/pubs/files/conesearch.html"
               plaintextref="yes"
               >cone search services</webref>
       whose title contains the term "Sloan".
       The <code>keepcols</code> filter takes the result and throws away
       all the columns except for <code>shortName</code> and
       <code>serviceUrl</code>, and these are written to the terminal
       in ASCII format.  This may be useful to find the service URL
       for a cone search service with particular data for use with
       the <ref id="multicone"><code>multicone</code></ref> command.
       </p></dd>
</dl>
</p>

</subsubsect>

</subsect>

<subsect id="tcat">
<subhead><title><code>tcat</code>: &tcat-purpose;</title></subhead>

<p><code>tcat</code> is a tool for concatenating tables one after the other.
If you have two tables T1 and T2 which contain similar columns, and you 
want to treat them as a single table, you can use <code>tcat</code>
to produce a new table whose metadata (row headings etc) comes from T1
and whose data consists of all the rows of T1 followed by all the rows
of T2.  This will only work if the columns of the two tables to be
joined have the same or compatible types in the same order; 
if they do not, you must use the <code>icmd</code> parameters to 
preprocess the input tables so that the column sequences are compatible.
</p>

<p>In the current release of STILTS, <code>tcat</code> is rather 
rudimentary: you can only join two tables at once, you must arrange
for the columns to be in the right order, and you may end up with
an unhelpful error if the columns in matching positions are not of
compatible types.  Behaviour will be improved in a future release.
</p>

&tcat-summary;

<subsubsect>
<subhead><title>Examples</title></subhead>

<p>Here are some examples of <code>tcopy</code>:
<dl>

<dt><verbatim>
stilts tcat obs1.fits obs2.fits out=combined.fits
</verbatim></dt>
<dd><p>Concatenates two similar observation catalogues to form a combined one.
    In this case, both input and output tables are FITS files.
    </p></dd>

<dt><verbatim>
stilts tcat ifmt1=ascii in1=obs1.txt ifmt2=ascii in2=ob2.txt omode=stats
</verbatim></dt>
<dd><p>Again two similar catalogues are joined, but in this case both
    are in ASCII format, and instead of writing the result to an
    output file, the resulting joined catalogue is examined to calculate
    its statistics, which are written to standard output.
    </p></dd>

<dt><verbatim>
stilts tcat in1=survey.vot.gz ifmt2=csv in2=more_data.csv
            icmd1='addskycoords fk5 galactic RA2000 DEC2000 GLON GLAT' \
            icmd1='keepcols "OBJ_ID GLON GLAT"' \
            icmd2='keepcols "ident gal_long gal_lat"' \
            omode=topcat
</verbatim></dt>
<dd><p>In this case we are trying to concatenate results from two tables
    which are quite dissimilar to each other.  In the first place,
    one is a VOTable (no <code>ifmt1</code> parameter is required since
    VOTables can be detected automatically), and the other is a 
    comma-separated-values file (for which the <code>ifmt2=csv</code> 
    parameter must be given).
    In the second place, the column structure of the two tables may be
    quite different.  By pre-processing the two tables using the
    <code>icmd1</code> &amp; <code>icmd2</code> parameters, we produce
    in each case an input table which consists of three columns of
    compatible types and meanings: an integer identifier and floating point
    galactic longitude and latitude coordinates.
    The second table contains such columns to start with,
    but the first table requires an initial step to convert 
    FK5 J2000.0 coordinates to galactic ones.
    <code>tcat</code> joins the two doctored tables together, to produce
    a table which contains only these three columns, with all the rows
    from both input tables, and sends the result directly 
    to a new or running instance of TOPCAT.
    </p></dd>

</dl>
</p>

</subsubsect>

</subsect>


<subsect id="tcopy">
<subhead><title><code>tcopy</code>: &tcopy-purpose;</title></subhead>

<p><code>tcopy</code> is a table copying tool.
It simply copies a table from one place to another, but since
you can specify the input and output formats as desired, it works
as a converter from any of the supported 
<ref id="inFormats" plaintextref="yes">input formats</ref> 
to any of the supported 
<ref id="outFormats" plaintextref="yes">output formats</ref>.
</p>

<p><code>tcopy</code> is just a stripped-down version of
<ref id="tpipe"><code>tpipe</code></ref> - it doesn't do anything
that <code>tpipe</code> can't, but the usage is slightly 
simplified.
It is provided as a drop-in replacement for the old
<code>tablecopy</code> (<code>uk.ac.starlink.table.TableCopy</code>)
tool which was supplied with earlier versions of STIL and TOPCAT - 
it has the same arguments and behaviour as <code>tablecopy</code>, 
but is implemented somewhat differently
and will in some cases be more efficient.
</p>

&tcopy-summary;

<subsubsect>
<subhead><title>Examples</title></subhead>

<p>Here are some examples of <code>tcopy</code> in use:
<dl>

<dt><verbatim>
stilts tcopy stars.fits stars.xml
</verbatim></dt>
<dd><p>Copies a FITS table to a VOTable.
    Since no input format is specified, the format is automatically 
    detected (FITS is one of the formats for which this is possible).
    Since no output format is specified, the <code>stars.xml</code>
    filename is examined to make a guess at the kind of output to write:
    the <code>.xml</code> ending is taken to mean a TABLEDATA-encoded
    VOTable.
    </p></dd>

<dt><verbatim>
stilts tcopy stars.fits stars.xml ifmt=fits ofmt=votable
</verbatim></dt>
<dd><p>Does the same as the previous example, but the input and output
    formats have been specified explicitly.
    </p></dd>

<dt><verbatim>
stilts tcopy ofmt=text http://remote.host/data/vizer.xml.gz#4 -
</verbatim></dt>
<dd><p>Prints the contents of a remote, compressed VOTable to the terminal in 
    a human-readable form.  The <code>#4</code> at the end of the URL
    indicates that the data from the fifth <code>TABLE</code> element
    in the remote document are to be used.  The gzip compression of
    the table is taken care of automatically.
    </p></dd>

<dt><verbatim>
stilts tcopy ifmt=csv ofmt=latex spec.csv
</verbatim></dt>
<dd><p>Converts a comma-separated values file to a LaTeX table environment,
    writing the result to standard output.
    </p></dd>

<dt><verbatim>
stilts -classpath /usr/local/jars/pg73jdbc3.jar \
       -Djdbc.drivers=org.postgresql.Driver \
       tcopy in="jdbc:postgresql://localhost/imsim#SELECT ra, dec, Imag FROM dqc" \
             ofmt=fits wfslist.cat
</verbatim></dt>
<dd><p>Makes an SQL query on a PostgreSQL database and writes the
    results to a FITS file.
    The whole command is shown here, to show that the 
    classpath is augmented to include the PostgreSQL
    driver class, and the driver class is named using the 
    <code>jdbc.drivers</code> system property.
    As you can see, using SQL from Java is a bit fiddly, 
    and there are other ways to perform this
    setup than on the command line - see <ref id="jdbcConfig"/>
    and <code><ref id="tpipe">tpipe</ref></code>'s 
    <code>omode=tosql</code> output mode.
    </p></dd>

</dl>
</p>

</subsubsect>

</subsect>

<subsect id="tcube">
<subhead><title><code>tcube</code>: &tcube-purpose;</title></subhead>

<p><code>tcube</code> constructs an N-dimensional histogram, or density map, 
from N columns of an input table, and writes it out as an
N-dimensional data cube.  The parameters you supply define which N
numeric columns of the input table you want to use and the dimensions 
(bounds and pixel sizes) of the output grid.  
Each table row then defines a point in N-dimensional space.  
The program goes through each row, and if the point that row
defines falls within the bounds of the output grid you have defined,
increments the value associated with the corresponding pixel.  
The resulting N-dimensional array, whose pixel values represent a 
count of the rows associated with that region of the N-dimensional space,
is then written out as a FITS file.
In one dimension, this gives you a normal histogram of a given variable.
In two dimensions it might typically be used to plot the density on
the sky of objects from a catalogue.
</p>

<p>As with some of the other generic table commands,
you can perform extensive pre-processing on the input table by
use of the <code>icmd</code> parameter before the actual cube 
counts are calculated.
</p>

&tcube-summary;

<subsubsect id="tcubeExamples">
<subhead><title>Examples</title></subhead>

<p>
<dl>

<dt><verbatim>
stilts tcube in=2QZ_6QZ_pubcat.fits out=ccm.fits \
             cols='Bj_R U_Bj Bj' binsizes='0.05 0.05 0.5' bounds='-2:1 -3:2 :'
</verbatim></dt>
<dd><p>Calculates a 3-dimensional colour-colour-magnitude grid from 
    three existing columns in a table.  The bin (pixel) sizes are specified.
    The data bounds are specified explicitly for the (first two) 
    colour dimensions, but for the (third) magnitude dimension it is 
    determined from the minimum and maximum values the data in 
    that column of the table.
    The output is a three-dimensional FITS cube.
    </p></dd>

<dt><verbatim>
stilts tcube in=iras_psc.vot out=iras_psc_map.fits \
             icmd='addskycoords fk5 galactic ra dec glat glon' \
             cols='glat glon' nbins='400 200'
</verbatim></dt>
<dd><p>Calculates a map of object densities in galactic coordinates from
    a catalogue of IRAS point sources.  The output is a two-dimensional
    FITS image representing the sky in galactic coordinates.
    Bounds are determined automatically from the data, and the number of
    pixels in each dimension (400 in latitude and 200 in longitude) are
    specified, which means that the pixel sizes don't have to be.
    Since the input table contains sky positions in equatorial 
    coordinates rather than galactic ones, the <code>addskycoords</code>
    filter is used to preprocess the data before the cube generation
    step (see <ref id="filterSteps"/>).
    </p></dd>

</dl>
</p>

</subsubsect>
</subsect>

<subsect id="tmatch2">
<subhead><title><code>tmatch2</code>: &tmatch2-purpose;</title></subhead>

<p><code>tmatch2</code> is an efficient and highly configurable 
tool for crossmatching pairs of tables.
It can match rows between tables on the basis of their relative position
in the sky, or alternatively using many other criteria such as 
separation in some isotropic or anisotropic Cartesian space, 
identity of a key value, or some combination of these;
the full range of match criteria is discussed in <ref id="MatchEngine"/>.
You can choose whether you want to identify all the matches or
only the closest,
and what form the output table takes, for instance matched rows only,
or all rows from one or both tables, or only the unmatched rows.
</p>

&tmatch2-summary;

<subsubsect>
<subhead><title>Examples</title></subhead>

<p>Here are some examples of using <code>tmatch2</code>
<dl>

<dt><verbatim>
stilts tmatch2 in1=obs_v.xml in2=obs_i.xml out=obs_iv.xml \
               matcher=sky values1="ra dec" values2="ra dec" params="2"
</verbatim></dt>
<dd><p>Takes two input catalogues (VOTables), one with observations in
    the V band and the other in the I band, and performs a match
    to find objects within 2 arcseconds of each other.
    The result is a new table containing only rows where a match was found.
</p></dd>

<dt><verbatim>
stilts tmatch2 survey.fits ifmt2=csv mycat.csv \
               icmd1='addskycoords fk4 fk5 RA1950 DEC1950 RA2000 DEC2000' \
               matcher=skyerr \
               params=10 values1="RA2000 DEC2000 POS_ERR"  values2="RA DEC 0" \
               join=2not1 omode=count
</verbatim></dt>
<dd><p>Here a comma-separated-values file is being compared with a FITS
    catalogue representing some survey results.
    Positions in the survey catalogue use the FK4 B1950.0 system,
    and so a preprocessing step is inserted to create new position columns 
    in the first input table using the FK5 J2000.0 system,
    which is what the other input table uses.
    The survey catalogue contains a POS_ERR column which gives the positional
    uncertainty of its entries, so the <code>skyerr</code> matcher is
    used, which takes account of this; the third entry in the 
    <code>values1</code> parameter is the POS_ERR column (in arcsec).
    Since the second input table has no positional uncertainty information,
    0 is used as the third entry in <code>values2</code>.
    The <code>params</code> still has to contain a value which gives the
    maximum error for matching (i.e. &gt;= the largest value in the
    POS_ERR column).
    The join type is <code>2not1</code>, which means the output table
    will only contain those entries which are in the second input table
    but not in the first one.
    The output table is not stored, but the number of rows it contains
    (the number of objects represented in the CSV file but not the survey)
    is written to the screen.
    </p></dd>

<dt><verbatim>
stilts tmatch2 ifmt1=ascii ifmt2=ascii int1=cat1.txt in2=cat2.txt \
               matcher=2d values1="X Y" values2="X Y" params="5" join=1and2 \
               ocmd='addcol XDIFF X_1-X_2; addcol Y_1-Y_2' \
               ocmd'keepcols "XDIFF YDIFF"' omode=stats
</verbatim></dt>
<dd><p>Two ASCII-format catalogues are matched, where rows are
considered to match if their X,Y positions are within 5 units of
each other in some Cartesian space.
The result of the matching operation is a table of all the matched rows,
containing columns called X_1, X_2, Y_1 and Y_2 (along with any others
in the input tables) - the _1 and _2 are appended to the names to
disambiguate them since the same column names appear in the two input tables.
To this result are added two new columns, representing the X and Y positional
difference between the rows from one input table and those from the other.
The <code>keepcols</code> filter then throws all the other columns away,
retaining only these difference columns.
The final two-column table is not stored anywhere, 
but (<code>omode=stats</code>) 
statistics including mean and standard deviation 
are calculated on its columns and displayed to the screen.
Having done all this, you can examine the average X and Y differences
between the two input tables for matched rows, and if they differ
significantly from zero, you can conclude that there is a systematic
error between the positions in the two input files.
</p></dd>

<dt><verbatim>
stilts tmatch2 in1=mgc.fits in2=6dfgs.xml join=1and2 find=all \
               matcher=sky+1d params='3 0.5' \
               values1='ra dec bmag' values2='RA2000 DEC2000 B_MAG" \
               out=pairs.fits
</verbatim></dt>
<dd><p>This performs a match with a matcher that combines <code>sky</code>
    and <code>1d</code> match criteria.  This means that the only
    rows which match are those which are
    <em>both</em> within 3 arcsec of each other on the sky
    <em>and</em> and within 0.5 blue magnitudes.
    Note that for both the <code>params</code> and the 
    <code>values1</code> and <code>values2</code> parameters,
    the items for the <code>sky</code> matcher (RA and DEC) 
    are listed first,
    followed by those for the <code>1d</code> matcher (in this case,
    blue magnitude).
    </p></dd>

</dl>
</p>

</subsubsect>

</subsect>

<subsect id="tpipe">
<subhead><title><code>tpipe</code>: &tpipe-purpose;</title></subhead>

<p><code>tpipe</code> performs all kinds of general purpose manipulations
which take one table as input.
It is extremely flexible, and can do the following things
amongst others:
<ul>
<li>calculate statistics</li>
<li>display metadata</li>
<li>select rows in various ways, including algebraically</li>
<li>define new columns as algebraic functions of old ones</li>
<li>delete or rearrange columns</li>
<li>sort rows</li>
<li>convert between table formats</li>
</ul>
and combine these operations.
You can think of it as a supercharged table copying tool.
</p>

<p>The basic operation of <code>tpipe</code> is that it reads an 
input table, performs zero or more processing steps on it, 
and then does something with the output.  There are therefore
three classes of things you need to tell it when it runs:
<dl>
<dt>Input table location</dt>
<dd><p>Specified by the <code>in</code>, <code>ifmt</code> and
    <code>istream</code> parameters.
    </p></dd>

<dt>Processing steps</dt>
<dd><p>Either provide a string giving steps as the value
    of one or more <code>cmd</code> parameters, or the name of a file
    containing the steps using the <code>script</code> parameter.
    The steps that you can perform are described in 
    <ref id="filterSteps"/>.
    </p></dd>

<dt>Output table destination</dt>
<dd><p>What happens to the output table is determined by the value of
    the <code>omode</code> parameter.  
    By default, <code>omode=out</code>,
    in which case the table is written to a new table file in a format
    determined by <code>ofmt</code>.  However, you can do other things
    with the result such as
    calculate the per-column statistics (<code>omode=stats</code>),
    view only the table and column metadata (<code>omode=meta</code>),
    display it directly in TOPCAT (<code>omode=topcat</code>) etc.
    </p></dd>
</dl>
See <ref id="pipes"/> for a more detailed explanation of these ideas.
</p>

<p>The parameters mentioned above are listed in detail in the next section.
</p>

&tpipe-summary;

<subsubsect id="tpipeExamples">
<subhead><title>Examples</title></subhead>

<p>Here are some examples of <code>tpipe</code> in use with explanations
of what's going on.  For simplicity these examples assume that you have the 
<code>stilts</code> script installed and are using a Unix-like shell;
see <ref id="invoke"/> for an explanation of how to invoke the command
if you just have the Java classes.
</p>

<p>
<dl>
<dt><verbatim>
stilts tpipe cat.fits
</verbatim></dt>
<dd><p>Writes a FITS table to standard output in human-readable form.
    Since no mode specifier is given, <code>omode=out</code> is assumed,
    and output is to standard output in <code>text</code> format.
    </p></dd>

<dt><verbatim>
stilts tpipe cmd='head 5' cat.fits.gz
</verbatim></dt>
<dd><p>Does the same as the last example, but with one processing step:
    only the first five rows of the table are output.  In this case,
    the input file is compressed using gzip - this is automatically 
    detected.
    </p></dd>

<dt><verbatim>
stilts tpipe ifmt=csv xxx.csv \
             cmd='keepcols "index ra dec"' \
             omode=out ofmt=fits xxx.fits
</verbatim></dt>
<dd><p>Reads from a comma-separated values file, writes to a FITS file,
    and discards all columns in the input table apart from INDEX, RA and DEC.
    Note the quoting in the <code>cmd</code> argument: the outer quotes
    are so that the argument of the <code>cmd</code> parameter itself
    (<code>keepcols "index ra dec"</code>)
    is not split up by spaces (to protect it from the shell), 
    and the inner quotes are to keep the 
    <code>colid-list</code> argument of the 
    <code>keepcols</code> command together.
    </p></dd>

<dt><verbatim><![CDATA[
stilts tpipe ifmt=votable \
             cmd='addcol IV_SUM "(IMAG+VMAG)"' \
             cmd='addcol IV_DIFF "(IMAG-VMAG)"' \
             cmd='delcols "IMAG VMAG"' \
             omode=out ofmt=votable \
       < tab1.vot \
       > tab2.vot
]]></verbatim></dt>
<dd><p>Replaces two columns by their sum and difference in a VOTable.
    Since neither the <code>in</code> nor <code>out</code> parameters
    have been specified, the input and output are actually byte 
    streams on standard input and standard output of the 
    <code>tpipe</code> command in this case.
    The processing steps first add a column representing the sum,
    then add a column representing the difference, then delete the 
    original columns.
    </p></dd>

<dt><verbatim>
stilts tpipe cmd='addskycoords -inunit sex fk5 gal \
                               RA2000 DEC2000 GAL_LONG GAL_LAT' \
             6dfgs.fits 6dfgs+gal.fits
</verbatim></dt>
<dd><p>Adds columns giving galactic coordinates to a table.
    Both input and output tables are FITS files.
    The galactic coordinates, stored in new columns called GAL_LONG and
    GAL_LAT, are calculated from FK5 J2000.0 coordinates
    given in the existing columns named RA2000 and DEC2000.
    The input (FK5) coordinates are represented as sexagesimal strings
    (hh:mm:ss, dd:mm:ss), and the output ones are numeric degrees.
    </p></dd>

<dt><verbatim>
stilts -disk tpipe 2dfgrs_ngp.fits \
                   cmd='keepcols "SEQNUM AREA ECCENT"' \
                   cmd='sort -down AREA' \
                   cmd='head 20'
</verbatim></dt>
<dd><p>Displays selected columns for the 20 rows with largest values in
    the AREA column of a FITS table.  First the columns of interest 
    are selected, then the rows are sorted into descending order by 
    the value of the AREA column, then the first 20 rows of the resulting
    table are selected, and the result is written to standard output.
    Since a sort is being performed here, it's not possible to do all
    the processing a row at a time, since all the AREA values
    must be available for comparison during the sort.
    Two things are done here to accommodate this fact: first the
    column selection is done before the sort, so that it's only a 3-column
    table which needs to be available for random access,
    reducing the temporary storage required.
    Secondly the <code>-disk</code> flag is supplied, which means that
    temporary disk files rather than memory 
    will be used for caching table data.
</p></dd>

<dt><verbatim>
stilts tpipe 2dfgrs_ngp.fits \
             cmd='keepcols "SEQNUM AREA ECCENT"' \
             cmd='sorthead -down 20 AREA'
</verbatim></dt>
<dd><p>Has exactly the same effect as the previous example.
    However, the algorithm used by the <code>sorthead</code> filter is
    in most cases faster and cheaper on memory (only 20 rows ever have
    to be stored in this case), so this is generally a better approach
    than combining the <code>sort</code> and <code>head</code> filters.
    </p></dd>

<dt><verbatim>
stilts tpipe omode=meta http://archive.org/data/survey.vot.Z
</verbatim></dt>
<dd><p>Outputs column and table metadata about a table.
    In this case the table is a compressed VOTable at the end of a URL.
    </p></dd>

<dt><verbatim>
stilts tpipe in=survey.fits 
             cmd='select "skyDistance(hmsToRadians(RA),dmsToRadians(DEC), \
                                      hmsToRadians(2,28,11),dmsToRadians(-6,49,45) \
                          &lt; 5 * ARC_MINUTE"' \
             omode=count
</verbatim></dt>
<dd><p>Counts the number of rows within a given 5 arcmin 
    cone of sky in a FITS table.
    The <code>skyDistance</code> function is an expression which
    calculates the distance between the position specified in a row
    (as given by its RA and DEC columns) and a given point on the sky
    (here, 02:28:11,-06:49:45).
    Since <code>skyDistance</code>'s arguments and return value are in
    radians, some conversions are required: the RA and DEC columns
    are sexagesimal strings which are converted using the
    <code>hmsToRadians</code> and <code>dmsToRadians</code> functions 
    respectively.  Different versions of these functions (ones which take
    numeric arguments) are used to convert the coordinates of the fixed
    point to radians. 
    The result is compared to a multiple of the 
    <code>ARC_MINUTE</code> constant, which is the size of an arcminute
    in radians.  Any rows of the input table for which this comparison
    is true are included in the output. 
    An alternative function, <code>skyDistanceDegrees</code> which works
    in degrees, is also available.
    The functions and constants used here are described in detail 
    in <ref id="uk.ac.starlink.ttools.func.Coords"/>.
    </p></dd>

<dt><verbatim><![CDATA[
stilts tpipe ifmt=ascii survey.txt \
             cmd='select "OBJTYPE == 3 && Z > 0.15"' \
             cmd='keepcols "IMAG JMAG KMAG"' \
             omode=stats
]]></verbatim></dt>
<dd><p>Calculate statistics on the I, J and K magnitudes of selected
    objects from a catalogue.  Only those rows with the given OBJTYPE
    and in the given Z range are included.  The minimum, maximum, 
    mean, standard deviation etc of the IMAG, JMAG and KMAG columns
    will be written to standard output.
    </p></dd>

<dt><verbatim>
stilts -classpath lib/drivers/mysql-connector-java.jar \
       -Djdbc.drivers=com.mysql.jdbc.Driver \
       tpipe in=x.fits cmd="explodeall" omode=tosql \
             protocol=mysql host=localhost database=ASTRO1 newtable=TABLEX \
             user=mbt
</verbatim></dt>
<dd><p>Writes a FITS table to an SQL table, converting array-valued columns
    to scalar ones.
    To make the SQL connection work properly, the classpath is augmented
    to include the path of the MySQL JDBC driver and the
    <code>jdbc.drivers</code> system property is set to the JDBC driver
    class name.  The output will be written as a new table named TABLEX
    in the MySQL database called ASTRO1 on a MySQL server on the
    local host.  The password, if required, will be prompted for,
    as would any of the other required parameters if they had not been
    given on the command line.
    Any existing table in ASTRO1 with the name TABLEX is overwritten.
    The only processing done here is by the <code>explodeall</code> command,
    which takes any columns which have fixed-size array values and
    replaces them in the output with multiple scalar columns.
    </p></dd>

<dt><verbatim>
java -classpath stilts.jar:lib/drivers/mysql-connector-java.jar
     -Djdbc.drivers=com.mysql.jdbc.Driver \
     uk.ac.starlink.ttools.Stilts \
     tpipe in=x.fits \
           cmd=explodeall \
           omode=out \
           out="jdbc:mysql://localhost/ASTRO1?user=mbt#TABLEX"
</verbatim></dt>
<dd><p>This does exactly the same as the previous example, but achieves it
   in a slightly different way.  In the first place, java is invoked 
   directly with the necessary flags rather than getting the 
   <code>stilts</code> script to do it.  Note that you cannot use java's
   <code>-jar</code> flag in this case, because doing it like that
   would not permit access to the additional classes that contain
   the JDBC driver.
   In the second place we use <code>omode=out</code> rather than 
   <code>omode=tosql</code>.  For this we need to supply an <code>out</code>
   value which encodes the information about the SQL connection and
   table in a special URL-like format.  As you can see, this is a bit
   arcane, which is why the <code>omode=tosql</code> mode can be a help.
   </p></dd>

<dt><verbatim>
stilts tpipe USNOB.FITS cmd='every 1000000' omode=stats
</verbatim></dt>
<dd><p>Calculates statistics on a selection of the rows in a catalogue,
    and writes the result to the terminal.
    In this example, every millionth row is sampled.
</p></dd>

</dl>
</p>
</subsubsect>

</subsect>


<subsect id="votcopy">
<subhead><title><code>votcopy</code>: &votcopy-purpose;</title></subhead>

<p>The VOTable standard provides for three basic encodings
of the actual data within each table: TABLEDATA, BINARY and FITS.
TABLEDATA is a pure-XML encoding, which is relatively easy for humans
to read and write.
However, it is verbose and not very efficient for transmission
and processing,
for which reason the more compact BINARY format has been defined.
FITS format shares the advantages of BINARY, but is more likely to
be used where a VOTable is providing metadata 'decoration' for
an existing FITS table.
In addition, the BINARY and FITS encodings may carry their data 
either inline 
(as the base64-encoded text content of a <code>STREAM</code> element)
or externally 
(referenced by a <code>STREAM</code> element's <code>href</code> attribute).
</p>

<p>These different formats have their different advantages and
disadvantages.  Since, to some extent, programmers are humans too,
much existing VOTable software deals in TABLEDATA format even though
it may not be the most efficient way to proceed.
Conversely, you might wish to examine the contents of a BINARY-encoded 
table without use of any software more specialised than a text editor.
So there are times when it is desirable to convert from one of
these encodings to another.
</p>

<p><code>votcopy</code> is a tool which translates between these 
encodings while
making a minimum of other changes to the VOTable document.
The processing may result in some changes to lexical details 
such as whitespace in start tags, but the element structure is not
modified.  Unlike <code><ref id="tpipe">tpipe</ref></code> it does not impose 
STIL's model of what constitutes a table on the data between
reading it in and writing it out, so subtleties dependent on
the exact structure of the VOTable document will not be mangled.  
The only important changes should be the contents of
<code>DATA</code> elements in the document.
</p>

&votcopy-summary;

<subsubsect>
<subhead><title>Examples</title></subhead>

<p>Normal use of <code>votcopy</code> is pretty straightforward.
We give here a couple of examples of its input and output.
</p>

<p>Here is an example VOTable document, <code>cat.vot</code>:
<verbatim><![CDATA[
   <VOTABLE>
   <RESOURCE>

   <TABLE name="Authors">
   <FIELD name="AuthorName" datatype="char" arraysize="*"/>
   <DATA>
   <TABLEDATA>
   <TR><TD>Charles Messier</TD></TR>
   <TR><TD>Mark Taylor</TD></TR>
   </TABLEDATA>
   </DATA>
   </TABLE>

   <RESOURCE>
   <COOSYS equinox="J2000.0" epoch="J2000.0" system="eq_FK4"/>
   <TABLE name="Messier Objects">
   <FIELD name="Identifier" datatype="char" arraysize="10"/>
   <FIELD name="RA" datatype="double" units="degrees"/>
   <FIELD name="Dec" datatype="double" units="degrees"/>
   <DATA>
   <TABLEDATA>
   <TR> <TD>M51</TD> <TD>202.43</TD> <TD>47.22</TD> </TR>
   <TR> <TD>M97</TD> <TD>168.63</TD> <TD>55.03</TD> </TR>
   </TABLEDATA>
   </DATA>
   </TABLE>
   </RESOURCE>

   </RESOURCE>
   </VOTABLE>
]]></verbatim>
Note that it contains more structure than just a flat table: there are
two <code>TABLE</code> elements, 
the <code>RESOURCE</code> element of the second one being nested
in the <code>RESOURCE</code> of the first.  
Processing this document using a generic table tool such as 
<code>tpipe</code> or <code>tcopy</code> would lose this structure.
</p>

<p>To convert the data encoding to BINARY format, we simply execute
<verbatim>
   stilts votcopy format=binary cat.vot
</verbatim>
and the output is
<verbatim><![CDATA[
   <?xml version="1.0"?>
   <VOTABLE>
   <RESOURCE>

   <TABLE name="Authors">
   <FIELD name="AuthorName" datatype="char" arraysize="*"/>
   <DATA>
   <BINARY>
   <STREAM encoding='base64'>
   AAAAD0NoYXJsZXMgTWVzc2llcgAAAAtNYXJrIFRheWxvcg==
   </STREAM>
   </BINARY>
   </DATA>
   </TABLE>

   <RESOURCE>
   <COOSYS equinox="J2000.0" epoch="J2000.0" system="eq_FK4"/>
   <TABLE name="Messier Objects">
   <FIELD name="Identifier" datatype="char" arraysize="10"/>
   <FIELD name="RA" datatype="double" units="degrees"/>
   <FIELD name="Dec" datatype="double" units="degrees"/>
   <DATA>
   <BINARY>
   <STREAM encoding='base64'>
   TTUxAAAAAAAAAEBpTcKPXCj2QEecKPXCj1xNOTcAAAAAAAAAQGUUKPXCj1xAS4PX
   Cj1wpA==
   </STREAM>
   </BINARY>
   </DATA>
   </TABLE>
   </RESOURCE>

   </RESOURCE>
   </VOTABLE>
]]></verbatim>
Note that both tables in the document have been translated to BINARY format.
The basic structure of the document is unchanged: the only differences 
are within the <code>DATA</code> elements.  If we ran
<verbatim>
   stilts votcopy format=tabledata
</verbatim>
on either this output or the original input then the output would
be identical (apart perhaps from whitespace) to the input table, 
since the data are originally in TABLEDATA format.
</p>

<p>To generate a VOTable document with the data in external files,
the <code>href</code> parameter is used.  We will output in FITS format
this time.  Executing:
<verbatim>
   stilts votcopy format=fits href=true cat.vot fcat.vot
</verbatim>
writes the following to the file <code>fcat.vot</code>:
<verbatim><![CDATA[
   ...
   <DATA>
   <FITS>
   <STREAM href="fcat-1.fits"/>
   </FITS>
   </DATA>
   ...
   <DATA>
   <FITS>
   <STREAM href="fcat-2.fits"/>
   </FITS>
   </DATA>
   ...
]]></verbatim>
(the unchanged parts of the document have been skipped here for brevity).
The actual data are written in two additional files in the same
directory as the output file, <code>fcat-1.fits</code> and 
<code>fcat-2.fits</code>.  These filenames are based on the 
main output filename, but can be altered using the <code>base</code>
flag if required.  Note this has also given you FITS binary table 
versions of all the tables in the input VOTable document, which can be 
operated on by normal FITS-aware software quite separately from the VOTable
if required.
</p>

</subsubsect>

</subsect>

<subsect id="votlint">
<subhead><title><code>votlint</code>: &votlint-purpose;</title></subhead>

<p>The VOTable standard, while not hugely complicated, has a number
of subtleties and it's not difficult to produce VOTable documents
which violate it in various ways.  In fact it's probably true to say
that most VOTable documents out there are not strictly legal.
In some cases the errors are small and a parser is likely to
process the document without noticing the trouble.  
In other cases, the errors are so serious that it's hard for
any software to make sense of it.
In many cases in between, different software will react in different
ways, in the worst case appearing to parse a VOTable but in 
fact understanding the wrong data.
</p>

<p><code>votlint</code> is a program which can check a VOTable document
and spot places where it does not conform to the VOTable standard,
or places which look like they may not mean what the author intended.
It is meant for use in two main scenarios:
<ol>
<li>For authors of VOTables and VOTable-producing software,
    to check that the documents they produce are legal and problem-free.
    </li>
<li>For users of VOTables (including authors of VOTable-processing software) 
    who are having problems with one and want to
    know whether it is the data or the software at fault.
    </li>
</ol>
</p>

<p>Validating a VOTable document against the VOTable schema or DTD 
of course goes a long way towards checking a VOTable document for errors
(though it's clear that many VOTable authors don't even go this far),
but it by no means does the whole job, simply because the schema/DTD
specification languages don't have the facilities 
to understand the data structure
of a VOTable document.  For instance the VOTable schema 
will allow any plain text content in a <code>TD</code> element, but whether
this makes sense in a VOTable depends on the <code>datatype</code>
attribute of the corresponding <code>FIELD</code> element.  There are many
other examples.
<code>votlint</code> tackles this by parsing the VOTable document 
in a way which understands its structure and assessing the content
as critically as it can.  For any incorrect or questionable content
it finds, it will output a short message describing the problem 
and giving its location in the document.  What you do with this
information is then up to you.
</p>

<p>Using <code>votlint</code> is very straightforward.  
The <code>votable</code> argument
gives the location (filename or URL) of a VOTable document.
Otherwise, the document will be read from standard input.
Error and warning messages will be written on standard error.
Each message is prefixed with the location at which the error was
found (if possible the line and column are shown, though this is
dependent on your JVM's default XML parser).
The processing is SAX-based, so arbitrarily long tables can
be processed without heavy memory use.
</p>

<p><code>votlint</code> can't guarantee to pick up every possible
error in a VOTable document, but it ought to pick up many of the
most serious errors that are commonly made in authoring VOTables.
</p>

&votlint-summary;

<subsubsect>
<subhead><title>Items Checked</title></subhead>

<p>Votlint checks that the XML input is well-formed, and, unless the
<code>valid=false</code> parameter is supplied, that it validates against the
1.0 or 1.1 (as appropriate) DTD.  Although VOTable 1.1 is properly
defined against an XML Schema rather than a DTD, in conjunction with
the other checks done, the DTD validation turns out to be pretty comprehensive.
Some of the DTD validity checks are also done by
<code>votlint</code> internally, so that some validity-type 
errors may give rise to more than one warning.  
In general, the program errs on the side of verbosity.
</p>

<p>In addition to these checks, the following checks are carried out,
and lead to ERROR reports if violations are found:
<ul>
<li><code>TD</code> contents incompatible
    <code>datatype</code>/<code>arraysize</code> attributes declared
    in <code>FIELD</code></li>
<li>BINARY data streams which don't match metadata 
    declared in <code>FIELD</code></li>
<li><code>PARAM</code> values incompatible with declared 
    <code>datatype</code>/<code>arraysize</code></li>
<li>Meaningless <code>arraysize</code> declarations</li>
<li>Array-valued <code>TD</code> elements with the wrong number of elements</li>
<li>Array-valued <code>PARAM</code> values with the wrong number of 
    elements</li>
<li><code>nrows</code> attribute on <code>TABLE</code> element different
    from the number of rows actually in the table</li>
<li><code>VOTABLE</code> <code>version</code> attribute is unknown</li>
<li><code>ref</code> attributes without matching <code>ID</code> elements 
    elsewhere in the document</li>
<li>Same <code>ID</code> attribute value on multiple elements.</li>
</ul>
</p>

<p>Additionally, the following conditions, which are not actually 
forbidden by the VOTable standard, will generate WARNING reports.
Some of these may result from harmless constructions, but it is
wise at least to take a look at the input which caused them:
<ul>
<li>Wrong number of <code>TD</code> elements in row of <code>TABLEDATA</code>
    table</li>
<li>Mismatch between VOTable and FITS column metadata for
    FITS data encoding</li>
<li><code>TABLE</code> with no <code>FIELD</code> elements</li>
<li>Use of deprecated attributes</li>
<li><code>FIELD</code> or <code>PARAM</code> elements with
    <code>datatype</code> of either
    <code>char</code> or <code>unicodeChar</code>
    and undeclared <code>arraysize</code> -
    this is a common error which can result in 
    ignoring all but the first character in <code>TD</code> elements from
    a column</li>
<li><code>ref</code> attributes which reference other elements by 
    <code>ID</code> where the reference makes no, or questionable sense
    (e.g. <code>FIELDref</code> references <code>FIELD</code> in a 
    different table)</li>
<li>Multiple sibling elements (such as <code>FIELD</code>s) with the
    same <code>name</code> attributes</li>
</ul>
</p>
</subsubsect>

<subsubsect>
<subhead><title>Examples</title></subhead>

<p>Here is a brief example of running <code>votlint</code> against
a (very short) imperfect VOTable document.  If the document looks like
this:
<verbatim><![CDATA[
  <VOTABLE version="1.1">
   <RESOURCE>
    <TABLE nrows="2">
     <FIELD name="Identifier" datatype="char"/>
     <FIELD name="RA" datatype="double"/>
     <FIELD name="Dec" datatype="double"/>
     <DESCRIPTION>A very small table</DESCRIPTION>
     <DATA>
      <TABLEDATA>
       <TR>
        <TD>Fomalhaut</TD>
        <TD>344.48</TD>
        <TD>-29.618</TD>
        <TD>HD 216956</TD>
       </TR>
      </TABLEDATA> 
     </DATA> 
    </TABLE>
   </RESOURCE>
  </VOTABLE>
]]></verbatim>
then the output of a <code>votlint</code> run looks like this:
<verbatim><![CDATA[
  INFO (l.4): No arraysize for character, FIELD implies single character
  ERROR (l.7): Element "TABLE" does not allow "DESCRIPTION" here.
  WARNING (l.11): Characters after first in char scalar ignored (missing arraysize?)
  WARNING (l.15): Wrong number of TDs in row (expecting 3 found 4)
  ERROR (l.18): Row count (1) not equal to nrows attribute (2)
]]></verbatim>
Note the warning at line 11 has resulted from the same error as the
one at line 4 - because the <code>FIELD</code> element has no
<code>arraysize</code> attribute, <code>arraysize="1"</code> 
(single character) is assumed,
while the author almost certainly intended <code>arraysize="*"</code>
(unknown length string).
</p>

<p>By examining these warnings you can see what needs to be done to
fix this table up.  Here is what it should look like:
<verbatim><![CDATA[
  <VOTABLE version="1.1">
   <RESOURCE>
    <TABLE nrows="1">                                <!-- change row count -->
     <DESCRIPTION>A very small table</DESCRIPTION>   <!-- move DESCRIPTION -->
     <FIELD name="Identifier" datatype="char" 
                              arraysize="*"/>        <!-- add arraysize -->
     <FIELD name="RA" datatype="double"/>
     <FIELD name="Dec" datatype="double"/>
     <DATA>
      <TABLEDATA>
       <TR>
        <TD>Fomalhaut</TD>
        <TD>344.48</TD>
        <TD>-29.618</TD>
       </TR>                                         <!-- remove extra TD -->
      </TABLEDATA>
     </DATA>
    </TABLE>
   </RESOURCE>
  </VOTABLE>
]]></verbatim>
When fed this version, <code>votlint</code> gives no warnings.
</p>

</subsubsect>

</subsect>

</sect>

<sect>
<subhead><title>Release Notes</title></subhead>

<p>This is STILTS, Starlink Tables Infrastructure Library Tool Set.
It is a collection of non-graphical utilites for general 
purpose table and VOTable manipulation developed by 
<webref url="http://www.starlink.ac.uk/">Starlink</webref>.

<dl>
<dt>Author</dt>
<dd><p>Mark Taylor (Starlink, Bristol University)</p></dd>

<dt>Email</dt>
<dd><p><webref url="mailto:m.b.taylor@bristol.ac.uk"
                          >m.b.taylor@bristol.ac.uk</webref></p></dd>

<dt>WWW</dt>
<dd><p><webref url="http://www.starlink.ac.uk/stilts/"
                   >http://www.starlink.ac.uk/stilts/</webref></p></dd>
</dl>

User comments, suggestions, requests and bug reports to the above address
are welcomed.
</p>

<subsect>
<subhead><title>Acknowledgements</title></subhead>

<p>The initial development of STILTS was done under the UK's 
now-deceased Starlink project, without which it would not have been written.
</p>

<p>Apart from the excellent Java 2 Standard Edition itself,
the following external libraries provide important parts of STILTS's
functionality:
<ul>
<li><webref url="http://galaxy.fzu.cz/JEL/">JEL</webref>
    (GNU) for algebraic expression evaluation</li>
<li><webref url="http://home.fnal.gov/~kuropat/HEALPIX/PixTools.html"
            >PixTools</webref>
    (Fermilab EAG) for HEALPix-based celestial sphere row matching</li>
<li><webref url="http://www.sdss.jhu.edu/htm/">HTM</webref>
    (Sloan Digital Sky Survey) for HTM-based celestial sphere row matching
    (now deprecated within STILTS)</li>
</ul>
Thanks in particular to Nickolai Kouropatkine and Chris Stoughton 
of Fermilab for writing the PixTools specially for use in STIL.
</p>

<p>Many people have contributed ideas and advice to the development of
STILTS and its related products.  I can't list all of them here,
but my thanks are especially due to the following:
<ul>
<li>Malcolm Currie (Starlink, RAL)</li>
<li>Clive Davenhall (Royal Observatory Edinburgh)</li>
<li>Peter Draper (Starlink, Durham)</li>
<li>David Giaretta (Starlink, RAL)</li>
<li>Clive Page (AstroGrid, Leicester)</li>
</ul>
</p>

</subsect>


<subsect id="versions">
<subhead><title>Version History</title></subhead>

<p>Releases to date have been as follows:
<dl>

<dt>Version 0.1b (29 April 2005)</dt>
<dd><p>First public release
    </p></dd>

<dt>Version 0.2b (30 June 2005)</dt>
<dd><p>
  <ul>
  <li>Added Times func class for MJD-ISO8601 time conversions.</li>
  <li>Fixed bug when doing NULL_ test expressions on first column in table.</li>
  </ul>
</p></dd>

<dt>Version 1.0b (30 September 2005)</dt>
<dd><p>This is the first non-experimental release of STILTS, and 
    it incorporates major changes and backward incompatibilities 
    since version 0.2b.
    </p>
    <p><dl>
       <dt>Parameter system</dt>
       <dd><p>The parameter system has undergone a complete rewrite;
           there is now only a single command "<code>stilts</code>",
           invoked using the <code>stilts</code> script or the 
           <code>stilts.jar</code> jar file, and the various tasks are
           named as subsequent arguments on the command line.
           Command arguments are supplied after that.
           The new invocation syntax is described in detail elsewhere in 
           this document.  As well as invocation features such
           as improved on-line help, optional prompting, 
           parameter defaulting, and more uniform access to common features,
           this will make it more straightforward to wrap these tasks 
           for use in non-command-line environments, such as behind a
           SOAP or CORBA interface, or in a CEA-like execution environment.
           </p></dd>

        <dt>Crossmatching</dt>
        <dd><p>A new command <code>tmatch2</code> has been introduced.
            This provides flexible and efficient crossmatching between
            two input tables.  Future releases will provide commands for
            intra-table and multi-table matching.
            </p></dd>

        <dt>Concatentation</dt>
        <dd><p>A new command <code>tcat</code> has been introduced, which
            allows two tables to be glued together top-to-bottom.
            This is currently working but very rudimentary - improvements
            will be forthcoming in future releases.
            </p></dd>

        <dt>Calculator</dt>
        <dd><p>A new utility command <code>calc</code> has been introduced,
            which performs one-line expression evaluations from the 
            command line.
            </p></dd>

        <dt>Pipeline filters</dt>
        <dd><p>The following new filter commands for use in <code>tpipe</code>
            and other commands have been introduced:
            <ul>
            <li><code>addskycoords</code>: calculates new 
                celestial coordinate pair from existing ones 
                (FK4, FK5, ecliptic, galactic, supergalactic)</li>
            <li><code>replacecol</code>: replaces column data,
                using existing metadata</li>
            <li><code>badval</code>: replaces given 'magic'
                value with null</li>
            <li><code>replaceval</code>: replaces given 'magic'
                value with any specified value</li>
            <li><code>tablename</code>: edits table name</li>
            <li><code>explodecols</code> and <code>explodecols</code> commands
                replace <code>explode</code></li>
            </ul>
        </p>
        <p>The new <code>stream</code> parameter of <code>tpipe</code> now
        allows you to write filter commands in an external file, to 
        facilitate more manageable command lines.
        </p>
        <p>Wildarding for column specification is now allowed for some
        filter commands.
        </p></dd>

        <dt>Algebraic functions</dt>
        <dd><p><ul>
            <li>New functions for converting time values between different
                coordinate systems (Modified Julian Date, ISO-8601,
                Julian Epoch and Besselian Epoch).</li>
            <li>New RANDOM special function.</li>
        </ul></p></dd>

        <dt>Documentation</dt>
        <dd><p>SUN/256 has undergone many changes.  Much of the tool
            documentation is now automatically generated from the code
            itself, which goes a long way to ensuring that the documentation
            is correct with respect to the current state of the code.
            </p></dd>

    </dl></p>
</dd>

<dt>Version 1.0-1b (7 October 2005)</dt>
<dd><p>Fixed jar file manifest bug which prevented working on Java 1.5</p></dd>

<dt>Version 1.1 (10 May 2006)</dt>
<dd><p>A number of new features and capabilities have been introduced:
    <dl>
    <dt><code>tcube</code> Command</dt>
    <dd><p>The new <ref id="tcube" plaintextref="yes">tcube</ref> command
        calculates N-dimensional histograms (density maps) from N columns
        of an input table and writes the result to a FITS file.</p></dd>

    <dt>Processing Filters</dt>
    <dd><p>The following new <ref id="filterSteps">filters</ref>
        have been added:
        <ul>
        <li><code>stats</code> filter provides the same information as
            the old <code>stats</code> output mode, but allows much more
            flexible use of the results.  It can also calculates many new
            quantities, including quantiles, skew and kurtosis.</li>
        <li><code>meta</code> filter provides the same information as
            the old <code>meta</code> output mode, but allows much more
            flexible use of the results.</li>
        <li><code>assert</code> filter provides in-pipeline logical
            assertions.</li>
        <li><code>uniq</code> filter collapses multiple adjacent identical 
            or similar rows.</li>
        <li><code>sorthead</code> filter provides a (usually) more
            efficient method of doing what you could previously do 
            by combining <code>sort</code> and <code>head</code> filters.</li>
        <li><code>colmeta</code> filter adds/modifies metadata for selected
            columns.</li>
        <li><code>check</code> filter checks table in stream - for debugging
            purposes only.</li>
        </ul>
        </p>
        <p>Additionally usage of the <code>sort</code> filter has been changed
        so that it can now do everything that <code>sortexpr</code> used to
        be able to do; <code>sortexpr</code> is now withdrawn.
        </p></dd>

    <dt>Output Modes</dt>
    <dd><p>The following new <ref id="outModes">output modes</ref>
        have been introduced:
        <ul>
        <li><code>plastic</code> mode broadcasts the table to
            one or all registered PLASTIC listeners.</li>
        <li><code>cgi</code> mode writes the table to standard output in a
            form suitable for output from a CGI script.</li>
        <li><code>discard</code> mode throws away the table.</li>
        </ul>
        and usage of the following has been modified:
        <ul>
        <li><code>topcat</code> mode now attempts to use PLASTIC 
            (amongst other methods) to contact TOPCAT.</li>
        <li><code>stats</code> and <code>meta</code> modes are mildly
            deprecated in favour of the corresponding new filters
            (see above).</li>
        </ul>
        </p></dd>

    <dt>Other new features</dt>
    <dd><p>
        <ul>
        <li>New IPAC table format input handler added.</li>
        <li>New <code>csv-noheader</code> format variant output handler
            added.</li>
        <li><code>roundDecimal</code> and <code>formatDecimal</code>
            functions introduced for more control over visual appearance
            of numeric values.</li>
        <li>Experimental facilities for automatically generating a CEA
            application description file.</li>
        </ul>
        </p></dd>

    <dt>Bug fixes and minor improvements</dt>
    <dd><p>
        <ul>
        <li>Now copes with 'K'-format FITS binary table columns
           (64-bit integers).</li>
        <li>Improved, though still imperfect, retention of table-wide
            metadata in VOTables.</li>
        <li>Distinctions between null and false values in boolean columns are
            handled more carefully for FITS and VOTable files.</li>
        <li>Efficiency improvement when writing FITS-plus format
            (now only requires a maximum of two passes rather than
            three of the input rows).</li>
        <li>Added the <code>mark.workaround</code> 
            <ref id="sysProperties">system property</ref> which can 
            optionally work around a bug in some input streams 
            ("Resetting to invalid mark" errors).</li>
        <li>Fixed a bug in Cartesian matching which failed to match
            if the required error in any dimension was zero.</li>
        <li>Fixed erroneous reports about unknown <code>ucd</code> and 
            <code>utype</code> attributes of TABLE element in 
            <code>votlint</code>.</li>
        <li>When joining tables, column name comparison to determine
            whether deduplication is required is now case-insensitive.</li>
        <li>Error message improved when no automatic format detection
            is attempted for streamed tables.</li>
        <li>Setting <code>istream=true</code> is now less likely to cause a
            "Can't re-read stream" error.</li>
        </ul>
        </p></dd>
    </dl>

</p></dd>

<dt>Version 1.2 (7 July 2006)</dt>
<dd><p>
    <dl>
    <dt>Column-oriented Storage</dt>
    <dd><p>New features for permitting column-oriented storage
        (<code>colfits</code> format, new <code>startable.storage</code> 
        policy "<code>sideways</code>") have been introduced.
        These can provide considerable efficiency improvements for
        certain tasks when working with very large (and especially wide)
        tables.
        </p></dd>
    <dt>New VO commands</dt>
    <dd><p>Added two new commands for querying Virtual Observatory services:
        <ul>
        <li><ref id="multicone"><code>multicone</code></ref>
                                - &multicone-purpose;</li>
        <li><ref id="regquery"><code>regquery</code></ref>
                                - &regquery-purpose;</li>
        </ul>
        These tasks are experimental and may be modified or renamed in
        future releases.
        </p></dd>
    <dt>Other items</dt>
    <dd><p>
        <ul>
        <li><code>transpose</code> filter added.</li>
        <li>Added flux conversion functions (Jansky&lt;-&gt;magnitude).</li>
        <li>ISO-8601 strings now permit times of 24:00:00 as they should.</li>
        </ul>
        </p></dd>
    </dl>
</p></dd>

<dt>Version 1.2-1 (3 August 2006)</dt>
<dd><p>
    <ul>
    <li>Tab-Separated Table (TST) format now supported for reading and 
        writing.</li>
    <li>New <code>setparam</code> and <code>clearparams</code> filters.</li>
    <li>Added ICRS coordinate system for <code>addskycoords</code>.</li>
    <li>TUCDnn header cards now used in FITS files to transmit UCDs
        (non-standard mechanism).</li>
    <li>Efficiency improvements for column-oriented access.</li>
    </ul>
    </p></dd>

<dt>Next version</dt>
<dd><p>
    <ul>
    <li>Direct MySpace access using <code>ivo:</code> or <code>myspace:</code>
        URLs now provided.</li>
    </ul>
    </p></dd>

</dl>
</p>
</subsect>

</sect>

</appendices>

</docbody>

</sun>
